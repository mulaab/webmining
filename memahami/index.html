<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="ie=edge"><meta name=description content="Repositori Kuliah Web Mining"><link href=https://mulaab.github.io/webmining/memahami/ rel=canonical><meta name=author content=Mulaab><meta name=lang:clipboard.copy content="Copy to clipboard"><meta name=lang:clipboard.copied content="Copied to clipboard"><meta name=lang:search.language content=en><meta name=lang:search.pipeline.stopwords content=True><meta name=lang:search.pipeline.trimmer content=True><meta name=lang:search.result.none content="No matching documents"><meta name=lang:search.result.one content="1 matching document"><meta name=lang:search.result.other content="# matching documents"><meta name=lang:search.tokenizer content=[\s\-]+><link rel="shortcut icon" href=../assets/images/favicon.png><meta name=generator content="mkdocs-1.1.2, mkdocs-material-4.4.0"><title>Memahami - Repositori Kuliah Web Mining</title><link rel=stylesheet href=../assets/stylesheets/application.4031d38b.css><link rel=stylesheet href=../assets/stylesheets/application-palette.224b79ff.css><meta name=theme-color content=#795548><script src=../assets/javascripts/modernizr.74668098.js></script><link href=https://fonts.gstatic.com rel=preconnect crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono&display=fallback"><style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style><link rel=stylesheet href=../assets/fonts/material-icons.css><link rel=stylesheet href=../stylesheets/extra.css><script>
  window.ga = window.ga || function() {
    (ga.q = ga.q || []).push(arguments)
  }
  ga.l = +new Date
  /* Setup integration and send page view */
  ga("create", "None", "auto")
  ga("set", "anonymizeIp", true)
  ga("send", "pageview")
  /* Register handler to log search on blur */
  document.addEventListener("DOMContentLoaded", () => {
    if (document.forms.search) {
      var query = document.forms.search.query
      query.addEventListener("blur", function() {
        if (this.value) {
          var path = document.location.pathname;
          ga("send", "pageview", path + "?q=" + this.value)
        }
      })
    }
  })
</script><script async src=https://www.google-analytics.com/analytics.js></script></head> <body dir=ltr data-md-color-primary=brown data-md-color-accent=indigo> <svg class=md-svg> <defs> <svg xmlns=http://www.w3.org/2000/svg width=416 height=448 viewbox="0 0 416 448" id=__github><path fill=currentColor d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg> </defs> </svg> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay data-md-component=overlay for=__drawer></label> <a href=#memahami-data-dan-pengambilan-data tabindex=1 class=md-skip> Skip to content </a> <header class=md-header data-md-component=header> <nav class="md-header-nav md-grid"> <div class=md-flex> <div class="md-flex__cell md-flex__cell--shrink"> <a href=https://mulaab.github.io/webmining/ title="Repositori Kuliah Web Mining" class="md-header-nav__button md-logo"> <i class=md-icon></i> </a> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--menu md-header-nav__button" for=__drawer></label> </div> <div class="md-flex__cell md-flex__cell--stretch"> <div class="md-flex__ellipsis md-header-nav__title" data-md-component=title> <span class=md-header-nav__topic> Repositori Kuliah Web Mining </span> <span class=md-header-nav__topic> Memahami </span> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <label class="md-icon md-icon--search md-header-nav__button" for=__search></label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=query data-md-state=active> <label class="md-icon md-search__icon" for=__search></label> <button type=reset class="md-icon md-search__icon" data-md-component=reset tabindex=-1> &#xE5CD; </button> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix> <div class=md-search-result data-md-component=result> <div class=md-search-result__meta> Type to start searching </div> <ol class=md-search-result__list></ol> </div> </div> </div> </div> </div> </div> <div class="md-flex__cell md-flex__cell--shrink"> <div class=md-header-nav__source> <a href=https://github.com/mulaab/webmining/ title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> mulaab/webmining </div> </a> </div> </div> </div> </nav> </header> <div class=md-container> <nav class=md-tabs data-md-component=tabs> <div class="md-tabs__inner md-grid"> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=.. title="Rencana Pembelajaran Semester" class="md-tabs__link md-tabs__link--active"> Rencana Pembelajaran Semester </a> </li> </ul> </div> </nav> <main class=md-main> <div class="md-main__inner md-grid" data-md-component=container> <div class="md-sidebar md-sidebar--primary" data-md-component=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary" data-md-level=0> <label class="md-nav__title md-nav__title--site" for=__drawer> <a href=https://mulaab.github.io/webmining/ title="Repositori Kuliah Web Mining" class="md-nav__button md-logo"> <i class=md-icon></i> </a> Repositori Kuliah Web Mining </label> <div class=md-nav__source> <a href=https://github.com/mulaab/webmining/ title="Go to repository" class=md-source data-md-source=github> <div class=md-source__icon> <svg viewbox="0 0 24 24" width=24 height=24> <use xlink:href=#__github width=24 height=24></use> </svg> </div> <div class=md-source__repository> mulaab/webmining </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=.. title="Rencana Pembelajaran Semester" class=md-nav__link> Rencana Pembelajaran Semester </a> </li> <li class=md-nav__item> <a href=../Pengantar/ title="Materi I" class=md-nav__link> Materi I </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc>Table of contents</label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=#memahami-data-dan-pengambilan-data title="Memahami Data dan Pengambilan data" class=md-nav__link> Memahami Data dan Pengambilan data </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#macam-macam-data title="Macam macam Data" class=md-nav__link> Macam macam Data </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#data-terstruktur title="Data Terstruktur" class=md-nav__link> Data Terstruktur </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#macam-macam-atribut title="Macam- macam atribut" class=md-nav__link> Macam- macam atribut </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#data-tidak-terstruktur title="Data Tidak Terstruktur" class=md-nav__link> Data Tidak Terstruktur </a> </li> <li class=md-nav__item> <a href=#bahasa-alami title="Bahasa Alami" class=md-nav__link> Bahasa Alami </a> </li> <li class=md-nav__item> <a href=#data-yang-dibangkitkan-oleh-mesin title="Data yang dibangkitkan oleh Mesin" class=md-nav__link> Data yang dibangkitkan oleh Mesin </a> </li> <li class=md-nav__item> <a href=#data-jaringan-atau-data-berbasis-graph title="Data jaringan atau data berbasis Graph" class=md-nav__link> Data jaringan atau data berbasis Graph </a> </li> <li class=md-nav__item> <a href=#data-audiovidio-dan-citra title="Data Audio,Vidio dan Citra" class=md-nav__link> Data Audio,Vidio dan Citra </a> </li> <li class=md-nav__item> <a href=#data-streamming title="Data streamming" class=md-nav__link> Data streamming </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#distribusi-data title="Distribusi Data" class=md-nav__link> Distribusi Data </a> </li> <li class=md-nav__item> <a href=#ekplorasi-data-tipe-numerik title="Ekplorasi data tipe Numerik" class=md-nav__link> Ekplorasi data tipe Numerik </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#analisa-univariat title="Analisa univariat" class=md-nav__link> Analisa univariat </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#fungsi-distribusi-kumulatif-empiris title="Fungsi distribusi  Kumulatif Empiris" class=md-nav__link> Fungsi distribusi Kumulatif Empiris </a> </li> <li class=md-nav__item> <a href=#fungsi-distribusi-kumulatif-invers title="Fungsi distribusi kumulatif Invers" class=md-nav__link> Fungsi distribusi kumulatif Invers </a> </li> <li class=md-nav__item> <a href=#fungsi-massa-probabilitas-empiris title="Fungsi massa Probabilitas Empiris" class=md-nav__link> Fungsi massa Probabilitas Empiris </a> </li> <li class=md-nav__item> <a href=#mengukur-kecenduran-terpusat title="Mengukur kecenduran terpusat" class=md-nav__link> Mengukur kecenduran terpusat </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mean title=Mean class=md-nav__link> Mean </a> </li> <li class=md-nav__item> <a href=#median title=Median class=md-nav__link> Median </a> </li> <li class=md-nav__item> <a href=#mode title=Mode class=md-nav__link> Mode </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mengukur-sebaran-data title="Mengukur Sebaran Data" class=md-nav__link> Mengukur Sebaran Data </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#rentang-range-quartil-and-rentang-interquartile title="Rentang (Range), Quartil, and Rentang Interquartile" class=md-nav__link> Rentang (Range), Quartil, and Rentang Interquartile </a> </li> <li class=md-nav__item> <a href=#variansi-dan-standar-deviasi title="Variansi dan Standar Deviasi" class=md-nav__link> Variansi dan Standar Deviasi </a> </li> <li class=md-nav__item> <a href=#skewness title=Skewness class=md-nav__link> Skewness </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#implementasi title=Implementasi class=md-nav__link> Implementasi </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#analisa-bivariate title="Analisa Bivariate" class=md-nav__link> Analisa Bivariate </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#fungsi-massa-probabilitas-gabungan-empiris title="Fungsi Massa Probabilitas Gabungan Empiris" class=md-nav__link> Fungsi Massa Probabilitas Gabungan Empiris </a> </li> <li class=md-nav__item> <a href=#mengukur-dispersi title="Mengukur Dispersi" class=md-nav__link> Mengukur Dispersi </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mean_1 title=Mean class=md-nav__link> Mean </a> </li> <li class=md-nav__item> <a href=#variansi title=Variansi class=md-nav__link> Variansi </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mengukur-keterkaitan title="Mengukur keterkaitan" class=md-nav__link> Mengukur keterkaitan </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#covarian title=Covarian class=md-nav__link> Covarian </a> </li> <li class=md-nav__item> <a href=#korelasi title=Korelasi class=md-nav__link> Korelasi </a> </li> <li class=md-nav__item> <a href=#matrik-kovarian title="Matrik  Kovarian" class=md-nav__link> Matrik Kovarian </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#analisa-multivariate title="Analisa Multivariate" class=md-nav__link> Analisa Multivariate </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mean_2 title=Mean class=md-nav__link> Mean </a> </li> <li class=md-nav__item> <a href=#matrik-kovarian_1 title="Matrik Kovarian" class=md-nav__link> Matrik Kovarian </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#atribut-kategorikal title="Atribut Kategorikal" class=md-nav__link> Atribut Kategorikal </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#variabel-bernouli title="Variabel Bernouli" class=md-nav__link> Variabel Bernouli </a> </li> <li class=md-nav__item> <a href=#ditribusi-binomial-banyaknya-kejadian title="Ditribusi binomial : banyaknya kejadian" class=md-nav__link> Ditribusi binomial : banyaknya kejadian </a> </li> <li class=md-nav__item> <a href=#variable-multivariate-bernoulli title="Variable multivariate Bernoulli" class=md-nav__link> Variable multivariate Bernoulli </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mengukur-jarak-data title="Mengukur Jarak Data" class=md-nav__link> Mengukur Jarak Data </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#mengukur-jarak-tipe-numerik title="Mengukur Jarak  Tipe Numerik" class=md-nav__link> Mengukur Jarak Tipe Numerik </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#minkowski-distance title="Minkowski Distance" class=md-nav__link> Minkowski Distance </a> </li> <li class=md-nav__item> <a href=#manhattan-distance title="Manhattan distance" class=md-nav__link> Manhattan distance </a> </li> <li class=md-nav__item> <a href=#euclidean-distance title="Euclidean distance" class=md-nav__link> Euclidean distance </a> </li> <li class=md-nav__item> <a href=#average-distance title="Average Distance" class=md-nav__link> Average Distance </a> </li> <li class=md-nav__item> <a href=#weighted-euclidean-distance title="Weighted euclidean distance" class=md-nav__link> Weighted euclidean distance </a> </li> <li class=md-nav__item> <a href=#chord-distance title="Chord distance" class=md-nav__link> Chord distance </a> </li> <li class=md-nav__item> <a href=#mahalanobis-distance title="Mahalanobis distance" class=md-nav__link> Mahalanobis distance </a> </li> <li class=md-nav__item> <a href=#cosine-measure title="Cosine measure" class=md-nav__link> Cosine measure </a> </li> <li class=md-nav__item> <a href=#pearson-correlation title="Pearson correlation" class=md-nav__link> Pearson correlation </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mengukur-jarak-atribut-binary title="Mengukur Jarak Atribut Binary" class=md-nav__link> Mengukur Jarak Atribut Binary </a> </li> <li class=md-nav__item> <a href=#mengukur-jarak-tipe-categorical title="Mengukur Jarak Tipe categorical" class=md-nav__link> Mengukur Jarak Tipe categorical </a> <nav class=md-nav> <ul class=md-nav__list> <li class=md-nav__item> <a href=#overlay-metric title="Overlay Metric" class=md-nav__link> Overlay Metric </a> </li> <li class=md-nav__item> <a href=#value-difference-metric-vdm title="Value Difference Metric (VDM)" class=md-nav__link> Value Difference Metric (VDM) </a> </li> <li class=md-nav__item> <a href=#minimum-risk-metric-mrm title="Minimum Risk Metric (MRM)" class=md-nav__link> Minimum Risk Metric (MRM) </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#mengukur-jarak-tipe-ordinal title="Mengukur Jarak Tipe Ordinal" class=md-nav__link> Mengukur Jarak Tipe Ordinal </a> </li> <li class=md-nav__item> <a href=#menghitung-jarak-tipe-campuran title="Menghitung Jarak Tipe Campuran" class=md-nav__link> Menghitung Jarak Tipe Campuran </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#referensi title=Referensi class=md-nav__link> Referensi </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content> <article class="md-content__inner md-typeset"> <h1>Memahami</h1> <h2 id=memahami-data-dan-pengambilan-data><strong><u>Memahami Data dan Pengambilan data</u></strong><a class=headerlink href=#memahami-data-dan-pengambilan-data title="Permanent link">&para;</a></h2> <h3 id=macam-macam-data>Macam macam Data<a class=headerlink href=#macam-macam-data title="Permanent link">&para;</a></h3> <p>Dalam data data mining dan maha data, Anda akan menemukan banyak jenis data yang berbeda, dan masing-masing cenderung membutuhkan alat dan teknik yang berbeda. Macam macam data dikelompokkan sebagai berikut <sup id=fnref:1><a class=footnote-ref href=#fn:1>1</a></sup>:</p> <ul> <li><em>Data terstruktur (structured)</em></li> <li><em>Data tidak terstruktur(unstructured</em></li> <li><em>Data bahasa alami(Natural Language)</em></li> <li><em>Data yang dibangkit oleh Mesin (Machined-Generated)</em></li> <li><em>Data Audio, Video,Citra</em></li> <li><em>Data Streamming</em></li> <li><em>Data berbasis Graph(Graph-based)</em></li> </ul> <h4 id=data-terstruktur>Data Terstruktur<a class=headerlink href=#data-terstruktur title="Permanent link">&para;</a></h4> <p>Data terstruktur adalah data yang bergantung pada model data dan yang dinyatakan dalam bentuk tabel dengan atribut} (kolom) dan baris. Data terstruktur mudah disimpan dalam database dalam bentuk tabel atau file excel (Ms Office), SQl (structure Query Language)sehingga mudah dilakukan query terhadap data tersebut. Tetapi realitanya banyak data yang ada dalam dalam bentuk data tidak terstruktur karena data dihasilkan oleh manusia dan mesin</p> <p> <center> <img alt=terstruktur src=../assets/images/structured.png width=60% height=60%> </center> </p> <p> <center> Gambar 2.1 Contoh data terstruktur.. </center> </p> <h5 id=macam-macam-atribut><strong>Macam- macam atribut</strong><a class=headerlink href=#macam-macam-atribut title="Permanent link">&para;</a></h5> <p>Atribut adalah data yang mewakili karakteristik atau fitur dari objek data. Atribut bisa disebut juga dengan dimensi, fitur, dan variabel yang istilah itu sering digunakan literatur. Dimensi istilah yang biasanya digunakan dalam data warehouse. Dalam literatur pembelajaran mesin cenderung menggunakan istilah fitur, sementara dalam bidang statistik lebih memilih menggunakan istilah variabel. Dalam penambangan data atau data miniing dan database biasa menggunakan istilah atribut atau fitur , dan dalam buku ini juga menggunakan istilah atribut atau fitur. Contoh atribut-atribut yang menggambarkan objek pelanggan dapat mencakup, misalnya ID pelanggan, nama, dan alamat. Nilai yang diamati untuk atribut tertentu dikenal sebagai nilai observasi. Sekumpulan atribut yang digunakan untuk menggambarkan objek disebut disebut dengan vektor atribut (atau vektor fitur. Distribusi data yang melibatkan satu atribut (atau variabel) disebut univariat. Distribusi bivariat melibatkan dua atribut, dan seterusnya. Jenis atribut ditentukan oleh nilai-nilai pada atribut tersebut yang mungkin nominal, biner,atau ordinal, atau numerik. Pada subbagian berikut, kami perkenalkan nilai nilai tersebut</p> <p><strong>Macam macam tipe data atribut</strong></p> <ul> <li><em>Atribut Nominal</em></li> </ul> <blockquote> <p>Nilai atribut nominal adalah simbol ataunama barang. Setiap nilai mewakili beberapa jenis kategori, kode, atau status, dan Atribut nominal juga disebut kategori. Nilai-nilainya tidak memiliki tingkatan nilai. Dalam ilmu komputer, nilainya juga dikenal sebagai enumerasi</p> <blockquote> <p><strong>Contoh</strong> : </p> <p>Misalkan warna rambut dan status perkawinan adalah dua atribut dari data orang. Nilai yang mungkin untuk warna rambut adalah hitam, coklat, pirang, merah, hitam pucat, abu-abu, dan putih. Status perkawinan memiliki nilai atribut lajang, menikah, bercerai, dan janda. Baik warna rambut maupun status perkawinan adalah atribut nominal. Contoh lain dari atribut nominal adalah atribut pekerjaan dengan nilai-nilainya adalah guru, dokter gigi, programmer, petani, dan sebagainya </p> </blockquote> </blockquote> <ul> <li><em>Atribut Biner</em></li> </ul> <blockquote> <p>Atribut biner adalah atribut nominal dengan hanya dua kategori atau status: 0 atau 1, di mana 0 biasanya berarti atribut itu tidak ada, dan 1 berarti itu ada. Atribut Biner disebut sebagai Boolean jika dinyatakan dengan benar (true) dan salah(false) </p> <blockquote> <p><strong>Contoh</strong> : </p> <p>Terdapat atribut yang menggambarkan merokok pada pasien, 1 menunjukkan bahwa pasien merokok,sementara 0 menunjukkan bahwa pasien tidak merokok. Demikian pula, seandainya ada pasien menjalani tes medis yang memiliki dua kemungkinan hasil. Atribut Tes medis bersifat biner, dengan nilai 1 berarti hasil tes untuk pasien positif, sedangkan 0 berarti hasilnya negatif. Atribut biner simetris jika keduanya emiliki nilai bobot yang sama; Artinya, tidak ada kekhususan mengenai hasil mana yang harus dikodekan sebagai 0 atau 1. Misalkan atribut gender yang dengan nila atributnya laki dan perempuan. Atribut biner adalah asimetris jika hasil dari nilai nilainya tidak sama pentingnya seperti hasil positif dan negatif dari tes medis untuk HIV. Dengan mengkodekan hasil yang paling penting, biasanya 1 (mis., HIV positif) dan yang lainnya dengan 0 (mis., HIV negatif)</p> </blockquote> </blockquote> <ul> <li><em>Atribut ordinal</em></li> </ul> <blockquote> <p>Atribut ordinal adalah atribut dengan nilai yang memiliki arti urutan atau peringkat di antara nilai nilai yang ada, tapi besarnya nilai yang berurutan tersebut tidak diketahui. Ukuran kecenderungan terpusat dari atribut ordinal dapat diwakili oleh modus dan median median (nilai tengah), tetapi tidak untuk nilai rata-rata.Perlu diperhatikan bahwa atribut nominal, biner, dan ordinal bersifat kualitatif. Artinya, atribut-atribut tersebut hanya menjelaskan sebuah fitur dari suatu objek tanpa memberikan ukuran atau kuantitas yang sebenarnya. Nilai-nilai atribut kualitatif biasanya merupakan katakata yang mewakili kategori</p> <blockquote> <p><strong>Contoh</strong>: </p> <p>Atribut ordinal Misalkan ukuran minuman yang tersedia di sebuah restoran cepat saji. Atribut nominal ini memiliki tiga nilai yang mungkin: kecil, sedang, dan besar. Nilai memiliki arti urutan yang (yang sesuai dengan ukuran minuman). Contoh atribut ordinal lainnya adalah pangkat dan jabatan profesi. Atribut ordinal berguna untuk melakukan penilaian subjektif terhadap kualitas sesuatu objek yang tidak dapat diukur secara obyektif; atribut ordinal sering digunakan dalam survei untuk peringkat. Dalam satu survei, para peserta diminta untuk menilai tingkat kepuasan mereka sebagai pelanggan.Kepuasan pelanggan memiliki kategori ordinal berikut ini: 0: sangat tidak puas,1: agak tidak puas, 2: netral, 3: puas, dan 4: sangat puas. Atribut ordinal juga dapat diperoleh dari iskritisasi nilai atribut numerik dengan membagi rentang nilai menjadi urutan kategoria</p> </blockquote> </blockquote> <ul> <li><em>Atribut Numerik</em></li> </ul> <blockquote> <p>Atribut numerik bersifat kuantitatif; Artinya, ini adalah kuantitas yang terukur, yang dinyatakan dengan bilangan bulat atau nilai riel. Atribut numerik dapat Atribut Skala Interval(interval-scaled) atau skala ration (ratio-scaled) </p> <ul> <li><strong>Atribut skala interval</strong> diukur pada dengan skala unit ukuran yang sama. Nilai - nilai Interval berskala memiliki urutan dan bisa positif, 0, atau negatif. Jadi, selain untuk memberikan peringkat nilai, atribut semacam itu memungkinkan kita untuk membandingkan dan mengukur perbedaan antar nilai</li> </ul> <blockquote> <p><strong>Contoh</strong>: </p> <p>Atribut suhu adalah Skala interval. Misalkan kita memiliki nilai suhu di luar ruangan untuk beberapa hari yang berbeda dari suatu objek. Dengan mengurutkan nilai, kita mendapatkan peringkat objek yang berkenaan dengan suhu. Selain itu, kita bisa mengukur perbedaan antara nilai.Misalnya, a suhu 20o C adalah lima derajat lebih tinggi dari suhu 15oC. Contoh lain kalender tahun adalah. Misalnya, tahun 2002 dan 2010 terpisah delapan tahun. Karena atribut skala interval adalah numerik, kita dapat menghitung nilai ratarata, ukuran median dan modus dari kecenderungan terpusat</p> </blockquote> <ul> <li><strong>Atribut Skala Ratio</strong> Atribut skala rasio adalah atribut numerik dengan melekat titik nol pada nilai atribut tersebut. Artinya, jika pengukuran adalah berskala rasio, kita dapat dapat mengatakan berapa kali dari nilai yang lain atau rasio dari nilai yang lain. Selain itu, nilai yang dipesan, dan kita juga bisa menghitung selisih antara nilai, serta mean, median, dan modus</li> </ul> <blockquote> <p><strong>Contoh</strong> </p> <p>Atribut tentang pengukuran berat badan, tinggi badan, jumlah kata dalam dokumen </p> </blockquote> </blockquote> <h4 id=data-tidak-terstruktur><strong>Data Tidak Terstruktur</strong><a class=headerlink href=#data-tidak-terstruktur title="Permanent link">&para;</a></h4> <p>Data tidak terstruktur adalah data yang tidak mudah dimasukkan ke dalam model data karena isi/kontennya spesifik atau bervariasi. Salah satu contoh data tidak terstruktur adalah data email. Meskipun email berisi elemen terstruktur seperti pengirim, judul, dan isi teks, terlalu banyak variasi dari isi yang terkandung dalamnya diantaranya dialek bahasa yang dipakai dan sebagainya. Email juga salah satu contoh data bahasa alami</p> <p> <center> <img alt=terstruktur src=../assets/images/unstructured.png width=60% height=60%> </center> </p> <p> <center> Gambar 2.2 Contoh Data email </center> </p> <h4 id=bahasa-alami><strong>Bahasa Alami</strong><a class=headerlink href=#bahasa-alami title="Permanent link">&para;</a></h4> <p>Dalam neuropsikologi , linguistik , dan filsafat bahasa , bahasa alami atau bahasa biasa adalah bahasa yang telah berevolusi secara alami pada manusia melalui penggunaan dan pengulangan tanpa perencanaan. Bahasa alami berbeda dengan bahasa yang dibangun untuk memprogramna komputer atau membangun logika nalar. Bahasa alami dikenal sebagai bahasa manusia misal bahasa indonesia, bahasa inggris dan lain lain. Didalam pemrosesan bahasa alami diperluangan pengetahuan ilmu linguistics, semantics, statistics and machine learning.Dengan pemrosesan bahasa alami membantu komputer untuk memahami bahasa yang telah diucapkan oleh manusia </p> <h4 id=data-yang-dibangkitkan-oleh-mesin><strong>Data yang dibangkitkan oleh Mesin</strong><a class=headerlink href=#data-yang-dibangkitkan-oleh-mesin title="Permanent link">&para;</a></h4> <p>Data yang dibangkitkan oleh mesin secara otomatis tanpa intervensi manusia. Data ini terus menerus dibangkitkan selama proses tertentu sedang berjalan. Misalkan data weblog dari mesin server yang dihasilkan dari hasil transaksi user dengan sistem web. Contoh lain adalah data yang dihasilkan dari implementasi internet of things misal perekaman suhu udara dan kelembaban udara dari daerah tertentu yang terhubung dengan pusat penyimpanan data tersebut. </p> <h4 id=data-jaringan-atau-data-berbasis-graph><strong>Data jaringan atau data berbasis Graph</strong><a class=headerlink href=#data-jaringan-atau-data-berbasis-graph title="Permanent link">&para;</a></h4> <p>Data graph adalah data yang dinyatakan dengan graph yang dalam matematika mengacu pada konsep teori graph. Data ini menunjukkan keterhubungan antara objek objek atau relasi antar objek objek dengan menggunakan struktur node, edge, dan karakteristik/sifat keterhubungan antar objek tersebut. Salah satu data graph adalah data keterhubungan orang dalam media sosial. Dengan memanfaatkan data graph media sosial kita dapat mengukur ukuran ukuran tertentu berdasarkan struktur yang dibentuknya. Misalkan menentukan pengaruh orang dalam struktur jaringan tersebut, apakah termasuk orang penting/berpengaruh atau bukan. Gambar berikut menunjukkan contoh data graph</p> <p> <center> <img alt=graph-data src="../assets/images/graph data.png" width=60% height=60%> </center> </p> <p> <center> Gambar 2.3 .Pertemanan dalam media sosial yang dinyataka dengan data graph </center> </p> <p>Database graph dapat digunakan untuk menyimpan data berbasis graph dan mengunakan query tertentu yaitu SPARQL</p> <h4 id=data-audiovidio-dan-citra><strong>Data Audio,Vidio dan Citra</strong><a class=headerlink href=#data-audiovidio-dan-citra title="Permanent link">&para;</a></h4> <p>Dengan perkembangan teknologi implementasi multimedia yang sangat pesat saat,data audio,video dan citra cukup besar dihasilkan dari transaksi bisnis. Dengan besarnya data yang dihasilkan membutuhkan proses pengolahan spesifik dari data tersebut untuk dimanfaatkan terutama dalam analisa data sain. Diantara pemanfaatan data mulitimedia tersebut adalah pengenalan objek, pengenala suara, segmentasi citra satelit dan banyak analisa lain yang dihasilkan dari data multimeda tersebut. </p> <h4 id=data-streamming><strong>Data streamming</strong><a class=headerlink href=#data-streamming title="Permanent link">&para;</a></h4> <p>Data Streaming adalah data yang dihasilkan secara terus-menerus oleh ribuan sumber data, yang biasanya mengirimkan catatan data secara bersamaan, dan dalam ukuran kecil (urutan Kilobyte). Data streaming mencakup berbagai macam data seperti logfile yang dihasilkan oleh pelanggan aplikasi seluler atau website Anda, transaksi e-commerce, informasi dari jejaring sosial, data geospasial, dan perangkat sensor yang terhubung atau instrumentasi di pusat data.</p> <p>Data ini perlu diproses secara berurutan dan bertahap secara record-by-record digunakan untuk berbagai macam analisis misalkan korelasi, agregasi, penyaringan, dan pengambilan sampel. Informasi yang diperoleh dari analisis tersebut memberikan petunjuk terhadap pelanggan mereka seperti penggunaan layanan mereka, aktivitas server, klik website, dan lain lain. Misalnya, dalam bisnis kita dapat melacak perubahan sentimen publik pada merek dan produk mereka dengan menganalisis aliran data media sosial, sehingga dapat merespons secara tepat baik waktu dan tindakan yang harus dilakukan</p> <h3 id=distribusi-data>Distribusi Data<a class=headerlink href=#distribusi-data title="Permanent link">&para;</a></h3> <p>Karakteristik utama dari data adalah distribusi probabilitasnya. Distribusi data yang paling dikenal adalah distribusi normal atau Gaussian. Distribusi ini ditemukan pada sistem fisik dimana data dibangkitkan secara acak. Fungsi dinyatakan dalam bentuk fungsi padat probabilitas(probability density function)</p> <p>$$ f ( x ) = \frac { 1 } { ( \sigma \sqrt { 2 } \pi ) } \frac { e ^ { - ( x - \mu ) ^ { 2 } } } { ( 2 \sigma ^ { 2 } ) } $$ Dimana <span><span class=MathJax_Preview>\sigma</span><script type=math/tex>\sigma</script></span> adalah standar deviasi dan <span><span class=MathJax_Preview>\mu</span><script type=math/tex>\mu</script></span> adalah mean. Persamaan ini menyatakan peluang variable acak dari suatu data <span><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span>. Kita menyatakan standar deviasi sebagai lebar kurva lonceng dan rata rata sebagai pusat. Kadangkala istilah variance digunakan dan ini adalah kuadrat dari standar deviasi. Standar deviasi pada dasarnya mengukur bagaimana sebaran data.</p> <p>Untuk memahami lebih jelasnya bagaimana fungsi tersebut digambarkan, berikut implementasinya data dengan distribusi normal yang memiliki rata-rata 1 dan variansinya 0.5</p> <p> <center> <img alt=normdis src=../assets/images/normdist.png width=60% height=60%> </center> </p> <p> <center> Gambar 2.4. Distribusi Data </center> </p> <div class=highlight><pre><span></span><code><span class=n>mu</span> <span class=o>=</span> <span class=mi>1</span> <span class=c1># rata-rata</span>
<span class=n>sigma</span> <span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mf>0.5</span><span class=p>)</span> <span class=c1># standar deviasi (akar dari varians)</span>
<span class=n>s</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>normal</span><span class=p>(</span><span class=n>mu</span><span class=p>,</span> <span class=n>sigma</span><span class=p>,</span> <span class=mi>1000</span><span class=p>)</span> <span class=c1># membangkitkan 1000 bilangan acak dgn distribusi norma</span>
<span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>

<span class=n>plt</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>bins</span><span class=p>,</span> <span class=mi>1</span><span class=o>/</span><span class=p>(</span><span class=n>sigma</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>pi</span><span class=p>))</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span> <span class=o>-</span> <span class=p>(</span><span class=n>bins</span> <span class=o>-</span> <span class=n>mu</span><span class=p>)</span><span class=o>**</span><span class=mi>2</span> <span class=o>/</span> <span class=p>(</span><span class=mi>2</span> <span class=o>*</span> <span class=n>sigma</span><span class=o>**</span><span class=mi>2</span><span class=p>)</span> <span class=p>),</span><span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;blue&#39;</span><span class=p>)</span>
<span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</code></pre></div> <h3 id=ekplorasi-data-tipe-numerik>Ekplorasi data tipe Numerik<a class=headerlink href=#ekplorasi-data-tipe-numerik title="Permanent link">&para;</a></h3> <p>Pada bagian ini kita membahas metode statistik dasar untuk analisis ekploarasi data atribut numerik. Kita membahas ukuran kecenderungan pusat (central tendency), ukuran dispersi atau sebaran, dan ukuran ketergantungan linier atau hubungan antara atribut. Kita menekankan hubungan antara probabilistik dan geometris dan aljabar dari sudut pandang data matriks</p> <h4 id=analisa-univariat>Analisa univariat<a class=headerlink href=#analisa-univariat title="Permanent link">&para;</a></h4> <p>Analisis univariat dilakukan pada atribut tunggal (<span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>); dengan demikian matriks data D bisa dianggap sebagai matriks <span><span class=MathJax_Preview>n × 1</span><script type=math/tex>n × 1</script></span>, atau sebagai vektor kolom, yang dianyatakan dengan kkk</p> <div> <div class=MathJax_Preview> X=\begin {pmatrix} \begin{array} { c } { X } \\ \hline x _ { 1 } \\ { x _ { 2 } } \\ { \vdots } \\ { x _ { n } } \end{array} \end {pmatrix} </div> <script type="math/tex; mode=display">
X=\begin {pmatrix} \begin{array} { c } { X } \\ \hline x _ { 1 } \\ { x _ { 2 } } \\ { \vdots } \\ { x _ { n } } \end{array} \end {pmatrix}
</script> </div> <p>dimana <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> adalah atribut numerik yang dimaksudkan, dengan <span><span class=MathJax_Preview>x_i \in \mathbb R</span><script type=math/tex>x_i \in \mathbb R</script></span> . <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> diasumsikan adalah variabel random, dengan setiap titik <span><span class=MathJax_Preview>x_i(1\leq i \leq n)</span><script type=math/tex>x_i(1\leq i \leq n)</script></span> , merupakan variabel acak. Kita asumsikan bawa data pengamatan adalah. Kami berasumsi bahwa data yang diamati adalah sampel acak yang diambil dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, artinya, setiap variabel <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> adalah saling bebas dan berdistribus sama (iid). Dalam sudut pandang vektor, kami memperlakukan sampel sebagai vektor n-dimensi, dan menulis <span><span class=MathJax_Preview>X \in \mathbb R^n</span><script type=math/tex>X \in \mathbb R^n</script></span> </p> <p>Secara umum, fungsi padat probabilitas atau fungsi mass <span><span class=MathJax_Preview>f(x)</span><script type=math/tex>f(x)</script></span> dan fungsi distribusi kumulatif <span><span class=MathJax_Preview>F(x)</span><script type=math/tex>F(x)</script></span> untuk atribut <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> keduanya tidak diketahui. Akan tetapi, kita dapat mengestimasi distribusi ini langsung dar data sample, juga juga memungkinkan kita untuk menghitung beberapa parameter penting populasi. </p> <p>Secara umum, fungsi padat probabilitas atau fungsi mass <span><span class=MathJax_Preview>f(x)</span><script type=math/tex>f(x)</script></span> dan fungsi distribusi kumulatif <span><span class=MathJax_Preview>F(x)</span><script type=math/tex>F(x)</script></span> untuk <span><span class=MathJax_Preview>F ^ { - 1 } ( q ) = \operatorname { min } { x | \hat { F } ( x ) \geq q } \quad \text { for } q \in [ 0,1 ]</span><script type=math/tex>F ^ { - 1 } ( q ) = \operatorname { min } { x | \hat { F } ( x ) \geq q } \quad \text { for } q \in [ 0,1 ]</script></span> atribut <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> keduanya tidak diketahui. Akan tetapi, kita dapat mengestimasi distribusi ini langsung dar data sample, juga juga memungkinkan kita untuk menghitung beberapa parameter penting populasi. </p> <h5 id=fungsi-distribusi-kumulatif-empiris>Fungsi distribusi Kumulatif Empiris<a class=headerlink href=#fungsi-distribusi-kumulatif-empiris title="Permanent link">&para;</a></h5> <p>Fungsi distribusi kumulatif empiris (CDF ) dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan</p> <p>$$ \hat { F } ( x ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i } \leq x ) $$ dimana </p> <div> <div class=MathJax_Preview> I(x_i\le x)=\Biggl\{\begin{array}={} 1 &amp; {\text {if }x_i\le x }\\ 0 &amp; {\text {if }x_i &gt; x}\end{array} </div> <script type="math/tex; mode=display">
I(x_i\le x)=\Biggl\{\begin{array}={}  1 & {\text  {if  }x_i\le x   }\\ 0 & {\text {if }x_i > x}\end{array}
</script> </div> <p>adalah variabel indikator biner yang menyatakan variabel indikator biner yang menunjukkan apakah kondisi yang diberikan terpenuhi atau tidak.</p> <h5 id=fungsi-distribusi-kumulatif-invers>Fungsi distribusi kumulatif Invers<a class=headerlink href=#fungsi-distribusi-kumulatif-invers title="Permanent link">&para;</a></h5> <p>Definisi fungsi distribusi kumulatif invers atau fungsi quantile untuk variabel acak <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> sebagai berikut : $$ F ^ { - 1 } ( q ) = \operatorname { min } { x | \hat { F } ( x ) \geq q } \quad \text { for } q \in [ 0,1 ] $$ Fungsi distribusi kumulatif Invers empiris dapat diperoleh dari persamaan (2)</p> <h5 id=fungsi-massa-probabilitas-empiris>Fungsi massa Probabilitas Empiris<a class=headerlink href=#fungsi-massa-probabilitas-empiris title="Permanent link">&para;</a></h5> <p>Fungsi massa probabilitas empiris dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan $$ \hat { f } ( x ) = P ( X = x ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i } = x ) $$ dimana </p> <div> <div class=MathJax_Preview> I(x_i\le x)=\Biggl\{\begin{array}={} 1 &amp; {\text {if }x_i= x }\\ 0 &amp; {\text {if }x_i \neq x}\end{array} </div> <script type="math/tex; mode=display">
I(x_i\le x)=\Biggl\{\begin{array}={}  1 & {\text  {if  }x_i= x   }\\ 0 & {\text {if }x_i \neq x}\end{array}
</script> </div> <p>Fungsi massa probabilitas empiris juga menempatkan massa probabitas <span><span class=MathJax_Preview>\frac {1}{n}</span><script type=math/tex>\frac {1}{n}</script></span>pada setipa titik <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span></p> <h5 id=mengukur-kecenduran-terpusat>Mengukur kecenduran terpusat<a class=headerlink href=#mengukur-kecenduran-terpusat title="Permanent link">&para;</a></h5> <p>Ukuran ini memberikan indikasi tentang konsentrasi massa probabilitas , nilai tengah dan lainnya.</p> <h6 id=mean>Mean<a class=headerlink href=#mean title="Permanent link">&para;</a></h6> <p>Mean juga disebut dengan nilai harapan dari variabel acak <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> adalah rata rata aritmetika dari nilai <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. Itu merupakan salah satu dari kecenderungan terpusat dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. </p> <p>Mean atau nilai harapan dari variabel acak <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> didefinisikan dengan $$ \mu = E [ X ] = \sum _ { x } x f ( x ) $$ diman <span><span class=MathJax_Preview>f(x)</span><script type=math/tex>f(x)</script></span> adalah fungsi massa probabilitas dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>.</p> <p>Nilai harapan dari variabel acak kontinu <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyakan dengan $$ \mu = E [ X ] = \int _ { - \infty } ^ { \infty } x f ( x ) d x $$ dimana <span><span class=MathJax_Preview>f(x)</span><script type=math/tex>f(x)</script></span> adalah fungsi padat probabilitas dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>.</p> <p><strong>Sample Mean</strong>. Sample mean adalah statistik, yaitu fungsi $ \hat { \mu } : { x _ { 1 } , x _ { 2 } , \ldots , x _ { n } } \rightarrow \mathbb R$, didefinisikan sebagai nilai rata-rata dari <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> : $$ \hat { \mu } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i } $$ nilai adalah sebagai pengestimasi nilai mean yang tidak diketahui dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. Nilai tersebut diperoleh dengan memasukkan dalam fungsi massa probabilitas empiris dalam persamaan (7) $$ \hat { \mu } = \sum _ { x } x \hat { f } ( x ) = \sum _ { x } x ( \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i } = x ) ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i } $$ <strong>Sample mean adalah tidak bias</strong> . Estimator <span><span class=MathJax_Preview>\hat { \theta }</span><script type=math/tex>\hat { \theta }</script></span> disebut dengan unbiased estimatore (stimator tidak bias) untuk parameter <span><span class=MathJax_Preview>\theta</span><script type=math/tex>\theta</script></span> jika <span><span class=MathJax_Preview>E[\hat \theta] = \theta</span><script type=math/tex>E[\hat \theta] = \theta</script></span> untuk setiap kemungkinan nilai dari <span><span class=MathJax_Preview>\theta</span><script type=math/tex>\theta</script></span> . Sample mean <span><span class=MathJax_Preview>\hat \mu</span><script type=math/tex>\hat \mu</script></span> adalah unbiased estimator untuk mean populasi <span><span class=MathJax_Preview>\mu</span><script type=math/tex>\mu</script></span> sehingga $$ E [ \hat { \mu } ] = E [ \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i } ] = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } E [ x _ { i } ] = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } \mu = \mu $$ dimana kita gunakan fakta bahwa variabel acak <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> adalah IID sesuai dengan <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, yang berarti bahwa mereka memiliki rata-rata <span><span class=MathJax_Preview>\mu</span><script type=math/tex>\mu</script></span> yang sama seperti <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> , yaitu,$ E [x_i] =\mu$ untuk semua <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span>. Kita juga menggunakan fakta bahwa fungsi ekpektasi <span><span class=MathJax_Preview>E</span><script type=math/tex>E</script></span> adalah linier operator yaitu untuk suatu dua bilangan acak <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dan <span><span class=MathJax_Preview>Y</span><script type=math/tex>Y</script></span> dan bilangan real <span><span class=MathJax_Preview>a</span><script type=math/tex>a</script></span> dan <span><span class=MathJax_Preview>b</span><script type=math/tex>b</script></span> , kita memiliki <span><span class=MathJax_Preview>E [ a X + b Y ] = a E [ X ] + b E [ Y ]</span><script type=math/tex>E [ a X + b Y ] = a E [ X ] + b E [ Y ]</script></span> </p> <p><strong>Robustnes</strong> Kita mengatakan bahwa statistik adalah robust jika tidak dipengaruhi oleh suatu nilai ekstrim ( misal outlier/pencilan) dalam data. Rata-rata sampel sayangnya tidak kuat karena ada satu nilai besar (outlier) dapat mejadikan rata-rata yang tidak sebenarnya. Ukuran yang lebih robust adalah trimmed mean yang didapatkan setalah mengabaikan sebagian kecil dari nilai nilai ekstrim pada salah satu ujungnya.</p> <h6 id=median><strong>Median</strong><a class=headerlink href=#median title="Permanent link">&para;</a></h6> <p>Median dari suatu variabel acak didefinisikan dengan nilai <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> sehingga $$ P ( X \leq m ) \geq \frac { 1 } { 2 } \text { and } P ( X \geq m ) \geq \frac { 1 } { 2 } $$ Degan kata lain, median <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> adalah nilai paling tengan (middle-most). Dalam istliah (invers) cumulatif distribution function , median <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> dinyatakan dengan $$ F ( m ) = 0.5 \text { or } m = F ^ { - 1 } ( 0.5 ) $$ Sample median dapat diperoleh dari Fungsi distribusi kumulatif invers atau fungsi distribusi kumulatif invers empiris dengan dihitung $$ \hat { F } ( m ) = 0.5 \text { atau } m = \hat { F } ^ { - 1 } ( 0.5 ) $$ Pendekatan paling sederhan untuk menghitung sample median adalah pertama kai dari mengurutkan semua nilai <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> <span><span class=MathJax_Preview>(i \in [1,n])</span><script type=math/tex>(i \in [1,n])</script></span> dengan urutan naik. Jika <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> adalah ganjil , media adalah nilai pada posisi <span><span class=MathJax_Preview>\frac {n+1}{2}</span><script type=math/tex>\frac {n+1}{2}</script></span> . Jika <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> adalah genap, nilai padan posisi <span><span class=MathJax_Preview>\frac {n}{2}</span><script type=math/tex>\frac {n}{2}</script></span> dan <span><span class=MathJax_Preview>\frac {n}{2}+1</span><script type=math/tex>\frac {n}{2}+1</script></span> adalah keduanaya median. </p> <p>Tidak seperti mean, media adalah robust, sehingga ia tidak dipengaruhi oleh banyak nilai extrim. Juga nilai tersebut terjadi dalam sample dan nilai yang bisa diasumsikan oleh variabel acak. </p> <h6 id=mode><strong>Mode</strong><a class=headerlink href=#mode title="Permanent link">&para;</a></h6> <p>Nilai <em>mode</em> dari variabel acak adalah nilai dimana fungsi massa probabilitas atau fungsi padat probabilitas mencapai nilai maximumnya, bergantung pada apakah <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> adalah diskrit atau kontinu. </p> <p><em>Sample mode</em> adalah nila untuk fungsi probabilitas empiris mencapai nilai maksimum, dinyatakan dengan $$ mode(X) =\arg \underset{x}{max} {\hat f(x)} $$ Mode ini mungkin bukan ukuran kecenderungan sentral yang sangat berguna untuk sampel, karena kemungkinan elemen yang tidak representatif menjadi elemen yang paling sering muncul. Selanjutnya, jika semua nilai dalam sampel berbeda, maka masing-masing akan menjadi mode</p> <p><strong><u>Contoh</u></strong>. <strong>(Sample Mean, Median, dan Mode)</strong>. Perhatikan atribut sepal length <span><span class=MathJax_Preview>(Xi)</span><script type=math/tex>(Xi)</script></span> dalam data iris. Data iris, dimana nilainya seperti yang ditunjukkan dalam tebel 1.2 . Sample mean dinyatakan dengan $$ \hat { \mu } = \frac { 1 } { 150 } ( 5.9 + 6.9 + \cdots + 7.7 + 5.1 ) = \frac { 876.5 } { 150 } = 5.843 $$ Gambar 2.1 menunjukkan semua dari 150 nilai sepal length dan sample mean. Gambar 2.2a menunjukkan fungsi distribusi kumulatif empiri dan gambar 2.2b menunjukkan fungsi distribusi kumulatif empiris untuk sepal length</p> <p>Karena <span><span class=MathJax_Preview>n=150</span><script type=math/tex>n=150</script></span> adalah genap, sample median adalah nilai pada posisi <span><span class=MathJax_Preview>\frac {n}{2}=75</span><script type=math/tex>\frac {n}{2}=75</script></span> dan <span><span class=MathJax_Preview>\frac {n}{2}+1=76</span><script type=math/tex>\frac {n}{2}+1=76</script></span> setelah diurutkan. Untuk sepal length kedua nilainya adalah 5.8, kemudian sample media adalah 5.8 . Dari fungsi distribusi kumulatif invers dalam gambar 2.2b, kita dapat melihat bahwa<br> $$ \hat { F } ( 5.8 ) = 0.5 \text { or } 5.8 = \hat { F } ^ { - 1 } ( 0.5 ) $$</p> <p>Sample mode untuk sepal length adalah 5. yang dapat dilihat dari frequency dari 5 dalam gambar 2.1. Massa probabilitas empiris pada <span><span class=MathJax_Preview>x=5</span><script type=math/tex>x=5</script></span> adalah $$ \hat { f } ( 5 ) = \frac { 10 } { 150 } = 0.067 $$</p> <h5 id=mengukur-sebaran-data>Mengukur Sebaran Data<a class=headerlink href=#mengukur-sebaran-data title="Permanent link">&para;</a></h5> <p>Kita sekarang membahas ukuran ukuran untuk menilai dispersi atau penyebaran data numerik. Ukuran-ukuran itu adalah rentang (range), kuantil, kuartil, persentil, dan rentang interkuartil. Semua itu adalah ringkasan lima angka, yang dapat ditunjukkan dengan boxplot, berguna dalam mengidentifikasi pencilan (outlier). Varians dan standar deviasi juga menunjukkan sebaran distribusi data.</p> <h6 id=rentang-range-quartil-and-rentang-interquartile><em>Rentang (Range), Quartil, and Rentang Interquartile</em><a class=headerlink href=#rentang-range-quartil-and-rentang-interquartile title="Permanent link">&para;</a></h6> <p>Misalkan <span><span class=MathJax_Preview>x_1, x_2, .. x_N</span><script type=math/tex>x_1, x_2, .. x_N</script></span> adalah sekumpulan pengamatan untuk atribut numerik, <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. Rentang adalah selisih antara nilai terbesar (maks ()) dan terkecil (min ()). Misalkan data untuk atribut X diurutkan dalam urutan naik.Bagilah data berdasarkan titik titik tertentu sehingga membagi distribusi data ukuran yang sama, seperti pada Gambar dibawah. Titik data ini disebut kuantil. 2-quantile adalah titik data yang membagi bagian bawah dan atas dari distribusi data. Ini sama dengan median. 4-kuantil adalah tiga titik data yang membagi distribusi data menjadi empat bagian yang sama; setiap bagian mewakili seperempat dari distribusi data. Ini lebih sering disebut sebagai kuartil. 100-kuantil lebih sering disebut sebagai persentil; mereka membagi distribusi data menjadi 100 data berukuran sama. Median, kuartil, dan persentil adalah bentuk kuantil yang paling banyak digunakan.</p> <p> <center> <img alt=percentile src=../assets/images/percentile.jpg width=60% height=60%> </center> </p> <p> <center> Gambar 2.6. Percentile data </center> </p> <p>Kuartil memberikan gambaran pusat distribus, penyebaran, dan bentuk distribusi. Kuartil satu, dilambangkan oleh Q1, adalah persentil ke-25. Nilai ini menunjukan 25% terendah dari data. Kuartil ketiga, dilambangkan oleh Q3, adalah persentil ke-75 - itu memisahkan data 75% dari terendah data (atau 25% dari tertinggi data. Kuartil kedua adalah persentil ke-50 atau median dari distribusi data. </p> <p>Jarak antara kuartil pertama dan ketiga adalah ukuran yang menyatakan rentang yang dicakup oleh bagian tengah data. Jarak ini disebut rentang interkuartil (IQR) dan dinyatakan dengan </p> <div> <div class=MathJax_Preview> I Q R = Q _ { 3 } - Q _ { 1 } </div> <script type="math/tex; mode=display"> I Q R = Q _ { 3 } - Q _ { 1 } </script> </div> <p>Dengan ukuran a kuartil Q1 dan Q3, dan median kita dapat mengidentifikasikan ada tidaknya pencilan (outlier) pada suatu data. Data pencilan atau outlier nilai data biasanya ada di setidaknya 1,5 × IQR di atas kuartil ketiga atau di bawah kuartil pertama</p> <p>Karena Q1, median, dan Q3 tidak berisi informasi tentang titik akhir (mis., Ekor) data, ringkasan yang lebih lengkap dari bentuk distribusi dapat diperoleh dengan memberikan nilai data terendah dan tertinggi juga. Ini dikenal sebagai ringkasan lima angka. Ringkasan lima nomor distribusi terdiri dari median (Q2), kuartil Q1 dan Q3, dan data terkecil dan terbesar( Minimum, Q1, Median, Q3, Maksimum)</p> <p>Boxplots adalah cara populer untuk memvisualisasikan distribusi. Boxplot menggabungkan ringkasan lima angka sebagai berikut: - Ujung kotak adalah kuartil dan panjang kotak adalah rentang interkuartil. - Median ditandai dengan garis di dalam kotak. - Dua garis (disebut whiskers) di luar kotak memanjang ke pengamatan terkecil (Minimum) dan terbesar (Maksimum)</p> <p>Outlier biasanya ada di dibawah <span><span class=MathJax_Preview>Q_1 – 1.5 \times IQR</span><script type=math/tex>Q_1 – 1.5 \times IQR</script></span> dan diatas $ Q_3 + 1.5 \times IQR$</p> <p> <center> <img alt=boxplot src=../assets/images/boxplot.jpg width=60% height=60%> </center> </p> <p> <center> Gambar 2.7. Boxplot </center> </p> <h6 id=variansi-dan-standar-deviasi><em>Variansi dan Standar Deviasi</em><a class=headerlink href=#variansi-dan-standar-deviasi title="Permanent link">&para;</a></h6> <p>Variansi dan standar deviasi adalah ukuran penyebaran data. Nilai-nilai tersebut menunjukkan bagaimana penyebaran distribusi data. Standar Deviasi yang rendah berarti bahwa pengamatan data cenderung sangat dekat dengan rata-rata, sedangkan deviasi standar yang tinggi menunjukkan data tersebar di sejumlah nilai-nilai besar.</p> <p>Varian dari pengamatan <span><span class=MathJax_Preview>N, x_1, x_2, ..., x_N</span><script type=math/tex>N, x_1, x_2, ..., x_N</script></span>, untuk atribut numerik X adalah</p> <div> <div class=MathJax_Preview> \sigma ^ { 2 } = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } ( x _ { i } - \overline { x } ) ^ { 2 } = ( \frac { 1 } { N } \sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \overline { x } ^ { 2 } </div> <script type="math/tex; mode=display"> \sigma ^ { 2 } = \frac { 1 } { N } \sum _ { i = 1 } ^ { N } ( x _ { i } - \overline { x } ) ^ { 2 } = ( \frac { 1 } { N } \sum _ { i = 1 } ^ { N } x _ { i } ^ { 2 } ) - \overline { x } ^ { 2 } </script> </div> <p>di mana $ \overline { x } $ adalah nilai rata-rata dari pengamatan, Standar deviasi,$\sigma $, dari pengamatan adalah akar kuadrat dari variansi, <span><span class=MathJax_Preview>\sigma^2</span><script type=math/tex>\sigma^2</script></span></p> <p>Sifat dasar dari standar deviasi, <span><span class=MathJax_Preview>\sigma</span><script type=math/tex>\sigma</script></span>, sebagai ukuran penyebaran data adalah sebagai berikut:</p> <ul> <li>Ukuran <span><span class=MathJax_Preview>\sigma</span><script type=math/tex>\sigma</script></span> mengeukur sebaran disekitar rata-rata dan harus dipertimbangkan bila rata-rata dipilih sebagai ukuran pusat data</li> <li><span><span class=MathJax_Preview>\sigma = 0</span><script type=math/tex>\sigma = 0</script></span> hanya jika tidak ada penyebaran data, hanya terjadi ketika semua pengamatan memiliki nilai sama, Jika tidak maka <span><span class=MathJax_Preview>\sigma &gt; 0</span><script type=math/tex>\sigma > 0</script></span></li> </ul> <h6 id=skewness><em>Skewness</em><a class=headerlink href=#skewness title="Permanent link">&para;</a></h6> <p>Derajat distorsi dari kurva lonceng simetris atau distribusi normal. Ini mengukur kurangnya simetri dalam distribusi data Untuk menghitung derajat distorisi dapat menggunakan Koefisien Kemencengan Pearson yang diperoleh dengan menggunakan nilai selisih rata-rata dengan modus dibagi simpangan baku. Koefisien Kemencengan Pearson dirumuskan sebagai berikut</p> <div> <div class=MathJax_Preview> s k=\frac{\overline{X}-M o}{s} </div> <script type="math/tex; mode=display">
s k=\frac{\overline{X}-M o}{s}
</script> </div> <p>dengan $$ \overline{X}-M o \approx 3(\overline{X}-M e) $$</p> <p>maka </p> <div> <div class=MathJax_Preview> s k \approx \frac{3(\overline{X}-M e)}{s} </div> <script type="math/tex; mode=display">
s k \approx \frac{3(\overline{X}-M e)}{s}
</script> </div> <p> <center> <img alt=skew src=../assets/images/skew.jpg width=60% height=60%> </center> </p> <p> <center> Gambar 2.8. Macam macam Kemiringan data (Skewness) </center> </p> <h5 id=implementasi>Implementasi<a class=headerlink href=#implementasi title="Permanent link">&para;</a></h5> <p>Untuk implementasi silahkan unduh <a href=https://github.com/mulaab/datamining/tree/master/assets/data/data.csv>data</a>.csv</p> <div class=highlight><pre><span></span><code><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
<span class=kn>from</span> <span class=nn>scipy</span> <span class=kn>import</span> <span class=n>stats</span>
<span class=n>df</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>&quot;data.csv&quot;</span><span class=p>,</span><span class=n>usecols</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>

<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;jumlah data  &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>count</span><span class=p>())</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;rata-rata   &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>())</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;nila minimal &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>min</span><span class=p>())</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Q1       &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>quantile</span><span class=p>(</span><span class=mf>0.25</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Q2          &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>quantile</span><span class=p>(</span><span class=mf>0.5</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Q3          &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>quantile</span><span class=p>(</span><span class=mf>0.75</span><span class=p>))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Nilai Max   &quot;</span><span class=p>,</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>())</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;kemencengan&quot;</span><span class=p>,</span><span class=s2>&quot;</span><span class=si>{0:.2f}</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>skew</span><span class=p>(),</span><span class=mi>2</span><span class=p>)))</span>
<span class=n>mode</span><span class=o>=</span><span class=n>stats</span><span class=o>.</span><span class=n>mode</span><span class=p>(</span><span class=n>df</span><span class=p>)</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Nilai modus </span><span class=si>{}</span><span class=s2> dengan jumlah </span><span class=si>{}</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=n>mode</span><span class=o>.</span><span class=n>mode</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>mode</span><span class=o>.</span><span class=n>count</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;kemencengan          &quot;</span> <span class=p>,</span><span class=s2>&quot;</span><span class=si>{0:.6f}</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>skew</span><span class=p>(),</span><span class=mi>6</span><span class=p>)))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Standar Deviasi   &quot;</span><span class=p>,</span><span class=s2>&quot;</span><span class=si>{0:.2f}</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>std</span><span class=p>(),</span><span class=mi>2</span><span class=p>)))</span>
<span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Variansi         &quot;</span><span class=p>,</span><span class=s2>&quot;</span><span class=si>{0:.2f}</span><span class=s2>&quot;</span><span class=o>.</span><span class=n>format</span><span class=p>(</span><span class=nb>round</span><span class=p>(</span><span class=n>df</span><span class=p>[</span><span class=s1>&#39;NilaiPreTest&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>var</span><span class=p>(),</span><span class=mi>2</span><span class=p>)))</span>
</code></pre></div> <h4 id=analisa-bivariate>Analisa Bivariate<a class=headerlink href=#analisa-bivariate title="Permanent link">&para;</a></h4> <p>Dalam analisa bivariate, kita memandang dua atribut pada waktu yang sama. Kita fokus untuk memahami keterkaitan atau kebergantunga antara dua variabel atau atribut tersebut, jika ada. Kita lalu membatasi pada dua variabel <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> , dengan <span><span class=MathJax_Preview>D</span><script type=math/tex>D</script></span> dinyatakan sebagai matrik dengan ukuran <span><span class=MathJax_Preview>n\times2</span><script type=math/tex>n\times2</script></span> </p> <div> <div class=MathJax_Preview> X=\begin {pmatrix} \begin{array}{ c c } { X _ { 1 } } &amp; { X _ { 2 } } \\ \hline x _ { 11 } &amp; { x _ { 12 } } \\ { x _ { 21 } } &amp; { x _ { 22 } } \\ { \vdots } &amp; { \vdots } \\ { x _ { n 1 } } &amp; { x _ { n 2 } } \end{array} \end {pmatrix} </div> <script type="math/tex; mode=display">
X=\begin {pmatrix} \begin{array}{ c c } { X _ { 1 } } & { X _ { 2 } } \\ \hline x _ { 11 } & { x _ { 12 } } \\ { x _ { 21 } } & { x _ { 22 } } \\ { \vdots } & { \vdots } \\ { x _ { n 1 } } & { x _ { n 2 } } \end{array} \end {pmatrix}
</script> </div> <p>Secara geometri, kita dapat memandang <span><span class=MathJax_Preview>D</span><script type=math/tex>D</script></span> dalam dua cara. Itu dapat dianggap sebagai <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> titik atau vektor dalam 2-ruang dimensi terhadap atribut <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> yaitu <span><span class=MathJax_Preview>x_i =(x_{i1},x_{i2})^T \in \mathbb R^2</span><script type=math/tex>x_i =(x_{i1},x_{i2})^T \in \mathbb R^2</script></span> .Selain itu dapat dilihat sebagai 2 titik atau vektor dalam <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span>-ruang dimensi yang berisi titik, yaitu setiap kolom adalah vektor dalam <span><span class=MathJax_Preview>\mathbb R^{n}</span><script type=math/tex>\mathbb R^{n}</script></span> sebagai berikut : $$ \left. \begin{array} { l } { X _ { 1 } = ( x _ { 11 } , x _ { 21 } , \ldots , x _ { n 1 } ) ^ { T } } \ { X _ { 2 } = ( x _ { 12 } , x _ { 22 } , \ldots , x _ { n 2 } ) ^ { T } } \end{array} \right. $$</p> <p>Dalam sudut pandang probabilistik, vektor kolom <span><span class=MathJax_Preview>X=(X_1,X_2)^T</span><script type=math/tex>X=(X_1,X_2)^T</script></span> dianggapa variabel acak bivariate dan titik titik <span><span class=MathJax_Preview>x _ { i } ( 1 \leq i \leq n )</span><script type=math/tex>x _ { i } ( 1 \leq i \leq n )</script></span> dinyatakan sebagai sampel acak yang diperoleh dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, yaitu <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> dianggap independent and identically distributed (iid) seperti <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. </p> <h5 id=fungsi-massa-probabilitas-gabungan-empiris><strong>Fungsi Massa Probabilitas Gabungan Empiris</strong><a class=headerlink href=#fungsi-massa-probabilitas-gabungan-empiris title="Permanent link">&para;</a></h5> <p>Fungsi Massa Probabilitas Gabungan Empiris untuk <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan $$ \hat { f } ( x ) = P ( X = x ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i } = x ) $$</p> <div> <div class=MathJax_Preview> \hat { f } ( x _ { 1 } , x _ { 2 } ) = P ( X _ { 1 } = x _ { 1 } , X _ { 2 } = x _ { 2 } ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i 1 } = x _ { 1 } , x _ { i 2 } = x _ { 2 } ) </div> <script type="math/tex; mode=display">
\hat { f } ( x _ { 1 } , x _ { 2 } ) = P ( X _ { 1 } = x _ { 1 } , X _ { 2 } = x _ { 2 } ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i 1 } = x _ { 1 } , x _ { i 2 } = x _ { 2 } )
</script> </div> <p>dimana <span><span class=MathJax_Preview>I</span><script type=math/tex>I</script></span> adalah variabel indikator yang bernilai 1 jika argumen argumennya benar</p> <p>$$ I ( x _ { i } = x ) = \left{ \begin{array} { l l } { 1 } &amp; { \text { jika } x _ { i 1 } = x _ { 1 } \text { dan } x _ { i 2 } = x _ { 2 } } \ { 0 } &amp; { \text { untuk yang lainnya } } \end{array} \right. $$ Seperti dalam kasus univariate, fungsi probabilitas menempatkan massa probabilitas <span><span class=MathJax_Preview>\frac {1}{n}</span><script type=math/tex>\frac {1}{n}</script></span> pada setiap objek dalam data sampel.</p> <h5 id=mengukur-dispersi>Mengukur Dispersi<a class=headerlink href=#mengukur-dispersi title="Permanent link">&para;</a></h5> <h6 id=mean_1><strong>Mean</strong><a class=headerlink href=#mean_1 title="Permanent link">&para;</a></h6> <p>Rata rata bivariate didefinisikan sebagai nilai harapan dari variabel acak vektor <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, didefinisikan sebagai berikut : $$ \mu = E [ X ] = E \left[ \left( \begin{array} { l } { X _ { 1 } } \ { X _ { 2 } } \end{array} \right) \right] = \left( \begin{array} { l } { E [ X _ { 1 } ] } \ { E [ X _ { 2 } ] } \end{array} \right) = \left( \begin{array} { l } { \mu _ { 1 } } \ { \mu _ { 2 } } \end{array} \right) $$</p> <p>Dengan kata lain, rata-rata bivariate adalah nilai harapan dari masing masing atribut.</p> <p>Rata-rata sampel dapat diperoleh dari <span><span class=MathJax_Preview>\hat f_{x_1}</span><script type=math/tex>\hat f_{x_1}</script></span> dan <span><span class=MathJax_Preview>\hat f_{x_2}</span><script type=math/tex>\hat f_{x_2}</script></span>, fungsi massa probabilitas empiris dari <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> , menggunakan persamaan (2.5). Dapat juga dihitung dari gabungan fungsi massa probabilitas empiris dalam persamaan (2.17) $$ \hat { \mu } = \sum _ { x } x \hat { f } ( x ) = \sum _ { x } x \left( \frac { 1 } { n } \sum _ { i = 1 } ^ { n } I ( x _ { i } = x )\right ) = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i } $$</p> <h6 id=variansi><strong>Variansi</strong><a class=headerlink href=#variansi title="Permanent link">&para;</a></h6> <p>Kita dapat menghitung variansi masing masing atribut, yaitu <span><span class=MathJax_Preview>\sigma_1^2</span><script type=math/tex>\sigma_1^2</script></span> untuk <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>\sigma_2^2</span><script type=math/tex>\sigma_2^2</script></span> untuk <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> mengggunkan persamaan (2.8). Variansi secara keseluruhan (1.4) dinyatakan dengan $$ var(D)=\sigma_1^2 +\sigma_2^2 $$ Variansi sampel <span><span class=MathJax_Preview>\hat \sigma_1^2 + \hat \sigma_2^2</span><script type=math/tex>\hat \sigma_1^2 + \hat \sigma_2^2</script></span> dapat diestimasi dengan menggunakanpersamaan (2.10) dan jumlah variansi sample adalah <span><span class=MathJax_Preview>\sigma_1^2 +\sigma_2^2</span><script type=math/tex>\sigma_1^2 +\sigma_2^2</script></span> </p> <h5 id=mengukur-keterkaitan><strong>Mengukur keterkaitan</strong><a class=headerlink href=#mengukur-keterkaitan title="Permanent link">&para;</a></h5> <h6 id=covarian><strong>Covarian</strong><a class=headerlink href=#covarian title="Permanent link">&para;</a></h6> <p>Kovarian antara dua atribut <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> mengukur keterkaitan antara kebergantungan linier diantaranya dan didefinisikan dengan $$ \sigma _ { 12 } = E [ ( X _ { 1 } - \mu _ { 1 } ) ( X _ { 2 } - \mu _ { 2 } ) ] $$ Dengan linieraritas dari harapan, kita miliki $$ \left. \begin{array}{l}{ \sigma _ { 12 } = E [ ( X _ { 1 } - \mu _ { 1 } ) ( X _ { 2 } - \mu _ { 2 } ) ] }\{ = E [ X _ { 1 } X _ { 2 } - X _ { 1 } \mu _ { 2 } - X _ { 2 } \mu _ { 1 } + \mu _ { 1 } \mu _ { 2 } ] }\{ = E [ X _ { 1 } X _ { 2 } ] - \mu _ { 2 } E [ X _ { 1 } ] - \mu _ { 1 } E [ X _ { 2 } ] + \mu _ { 1 } \mu _ { 2 } }\{ = E [ X _ { 1 } X _ { 2 } ] - \mu _ { 1 } \mu _ { 2 } }\{ = E [ X _ { 1 } X _ { 2 } ] - E [ X _ { 1 } ] E [ X _ { 2 } ] }\end{array} \right. $$ Persamaan (2.21) dapat dianggap sebagai generalisasi dari variansi univariate persamaan (2.9) pada kasus bivariate.</p> <p>Jika <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> adalah variabel acak saling bebas, maka kita dapat simpulkan bahwa covariannya adalah nol. Ini karena jika <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> adalah saling bebas, maka kita memiliki<br> $$ E [ X _ { 1 } X _ { 2 } ] = E [ X _ { 1 } ] \cdot E [ X _ { 2 } ] $$ yang pada akhirnya menyiratkan bahwa $$ \sigma{12}= 0 $$</p> <p>Namaun sebaliknya tidak benar. Yaitu jika <span><span class=MathJax_Preview>\sigma_{12}=0</span><script type=math/tex>\sigma_{12}=0</script></span>, kita tidak dapat mengklaim bahwa $X_1 $ dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> adalah saling bebas. Semuanya kita katakan bahwa tidak adalah kebergantung linier antara keduanya. Kovarian sampel antra <span><span class=MathJax_Preview>X1</span><script type=math/tex>X1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> dinyatakan dengan $$ \hat { \sigma } _ { 12 } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( x _ { i 1 } - \hat { \mu } _ { 1 } ) ( x _ { i 2 } - \hat { \mu } _ { 2 } ) $$</p> <h6 id=korelasi><strong>Korelasi</strong><a class=headerlink href=#korelasi title="Permanent link">&para;</a></h6> <p>Korelasi antara variabel <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> adalah standarisasi kovarian, yang didapatkan dengan menormalisasi kovarian dengan standar deviasi masing masing variabel dinyatakan dengan </p> <div> <div class=MathJax_Preview> \rho _ { 12 } = \frac { \sigma _ { 12 } } { \sigma _ { 1 } \sigma _ { 2 } } = \frac { \sigma _ { 12 } } { \sqrt { \sigma _ { 1 } ^ { 2 } \sigma _ { 2 } ^ { 2 } } } $$ Korelasi sample untuk atribut $X_1$ dan $X_2$ dinyatakan dengan $$ \hat { \rho } _ { 12 } = \frac { \hat { \sigma } _ { 12 } } { \hat { \sigma } _ { 1 } \hat { \sigma } _ { 2 } } = \frac { \sum _ { i = 1 } ^ { n } ( x _ { i 1 } - \hat { \mu } _ { 1 } ) ( x _ { i 2 } - \hat { \mu } _ { 2 } ) } { \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i 1 } - \hat { \mu } _ { 1 } ) ^ { 2 } \sum _ { i = 1 } ^ { m } ( x _ { i 2 } - \hat { \mu } _ { 2 } ) ^ { 2 } } } </div> <script type="math/tex; mode=display">
\rho _ { 12 } = \frac { \sigma _ { 12 } } { \sigma _ { 1 } \sigma _ { 2 } } = \frac { \sigma _ { 12 } } { \sqrt { \sigma _ { 1 } ^ { 2 } \sigma _ { 2 } ^ { 2 } } }
$$
Korelasi sample untuk atribut $X_1$ dan $X_2$ dinyatakan dengan 
$$
\hat { \rho } _ { 12 } = \frac { \hat { \sigma } _ { 12 } } { \hat { \sigma } _ { 1 } \hat { \sigma } _ { 2 } } = \frac { \sum _ { i = 1 } ^ { n } ( x _ { i 1 } - \hat { \mu } _ { 1 } ) ( x _ { i 2 } - \hat { \mu } _ { 2 } ) } { \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i 1 } - \hat { \mu } _ { 1 } ) ^ { 2 } \sum _ { i = 1 } ^ { m } ( x _ { i 2 } - \hat { \mu } _ { 2 } ) ^ { 2 } } }
</script> </div> <h6 id=matrik-kovarian><strong>Matrik Kovarian</strong><a class=headerlink href=#matrik-kovarian title="Permanent link">&para;</a></h6> <p>Variansi dari untuk dua atribut <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dan <span><span class=MathJax_Preview>X_2</span><script type=math/tex>X_2</script></span> dapat diringkas dalam matrik covarianse bujursangkar denga ukuran $2 \times 2 $ dinyatakan dengan $$ \left. \begin{array}{l}{ \Sigma = E [ ( X - \mu ) ( X - \mu ) ^ { T } ] }\{ = E \left[ \left( \begin{array} { c } { X _ { 1 } - \mu _ { 1 } } \ { X _ { 2 } - \mu _ { 2 } } \end{array} \right) ( X _ { 1 } - \mu _ { 1 } \quad X _ { 2 } - \mu _ { 2 } ) \right ] }\{ = \left( \begin{array} { c c } { E [ ( X _ { 1 } - \mu _ { 1 } ) ( X _ { 1 } - \mu _ { 1 } ) ] } &amp; { E [ ( X _ { 1 } - \mu _ { 1 } ) ( X _ { 2 } - \mu _ { 2 } ) ] } \ { E [ ( X _ { 2 } - \mu _ { 2 } ) ( X _ { 1 } - \mu _ { 1 } ) ] } &amp; { E [ ( X _ { 2 } - \mu _ { 2 } ) ( X _ { 2 } - \mu _ { 2 } ) ] } \end{array} \right) }\{ = \left( \begin{array} { c c } { \sigma _ { 1 } ^ { 2 } } &amp; { \sigma _ { 12 } } \ { \sigma _ { 21 } } &amp; { \sigma _ { 2 } ^ { 2 } } \end{array} \right) }\end{array} \right. $$ Karena <span><span class=MathJax_Preview>\sigma_{12}=\sigma_{21}</span><script type=math/tex>\sigma_{12}=\sigma_{21}</script></span>, $\Sigma $ adalah matrik simetris. Matrik vovarian merekam variansi tertentu atribut pada diagonal utamanya, dan informasi covarian pada elemen element bukan diagonal. Total variance dari dua atribut dinyatakan sebagai jumlah elemen elemen diagonal dari $ \Sigma $ , yang juga disebut <em>trace</em> dari $ \Sigma $ dinyatakan dengan $$ \operatorname { var } ( D ) = \operatorname { tr } ( \Sigma ) = \sigma _ { 1 } ^ { 2 } + \sigma _ { 2 } ^ { 2 } $$ Kita segera memiliki $ tr(\Sigma)\geq 0$ </p> <p>Secara umum covarian adalah non-negatif, karena $$ | \Sigma | = \operatorname { det } ( \Sigma ) = \sigma _ { 1 } ^ { 2 } \sigma _ { 2 } ^ { 2 } - \sigma _ { 12 } ^ { 2 } = \sigma _ { 1 } ^ { 2 } \sigma _ { 2 } ^ { 2 } - \rho _ { 12 } ^ { 2 } \sigma _ { 1 } ^ { 2 } \sigma _ { 2 } ^ { 2 } = ( 1 - \rho _ { 12 } ^ { 2 } ) \sigma _ { 1 } ^ { 2 } \sigma _ { 2 } ^ { 2 } $$</p> <p>dimana kitu gunakan persamaan (2.23), yaiut <span><span class=MathJax_Preview>\rho_{12}\sigma_1\sigma_2</span><script type=math/tex>\rho_{12}\sigma_1\sigma_2</script></span>. dengan <span><span class=MathJax_Preview>|\Sigma|</span><script type=math/tex>|\Sigma|</script></span> adalah determinan dari matrik kovarian. Perhatikan bahwa <span><span class=MathJax_Preview>|\rho_{12}|\leq 1</span><script type=math/tex>|\rho_{12}|\leq 1</script></span> menyebabkan <span><span class=MathJax_Preview>\rho_{12}^2 \leq 1</span><script type=math/tex>\rho_{12}^2 \leq 1</script></span> sehingga det <span><span class=MathJax_Preview>(\Sigma) \geq 1</span><script type=math/tex>(\Sigma) \geq 1</script></span> furthermore determinannya adalah non-negative.</p> <p>Matrik kovarian sampel dinyatakan dengan $$ \hat { \Sigma } = \left( \begin{array} { l l } { \hat { \sigma } _ { 1 } ^ { 2 } } &amp; { \hat { \sigma } _ { 12 } } \ { \hat { \sigma } _ { 12 } } &amp; { \hat { \sigma } _ { 2 } ^ { 2 } } \end{array} \right) $$ Matrik kovarian sampe $ \hat \Sigma$ memilki karakteristik sama seperti <span><span class=MathJax_Preview>\Sigma</span><script type=math/tex>\Sigma</script></span> , yaitu simetris dan <span><span class=MathJax_Preview>|\hat \Sigma| \geq 0</span><script type=math/tex>|\hat \Sigma| \geq 0</script></span> dan itu dapat digunakan untum memudahkan mendapatkan total sampel dan variansi secara umum</p> <p><strong>Contoh (Rata rata Sampel dan Covarian)</strong></p> <p>Perhatikan atribut sepal length dan sepal width untuk data iris, seperti yang diplot dalam gambar 2.4. Ada n=150 data dalam <span><span class=MathJax_Preview>d=2</span><script type=math/tex>d=2</script></span> ruang dimensi. Rata rata sampel adalah $$ \hat { \mu } = \left( \begin{array} { l } { 5.843 } \ { 3.054 } \end{array} \right) $$ Matrik covarian dinyatakan dengan $$ \hat { \Sigma } = \left( \begin{array} { r r } { 0.681 } &amp; { - 0.039 } \ { - 0.039 } &amp; { 0.187 } \end{array} \right) $$ Variansi untuk sepal length adalah <span><span class=MathJax_Preview>\hat \sigma_1^2=0.681</span><script type=math/tex>\hat \sigma_1^2=0.681</script></span> dan sepal width adalah <span><span class=MathJax_Preview>\hat \sigma_2^2=0.187</span><script type=math/tex>\hat \sigma_2^2=0.187</script></span>. Covarian antara dua atribut adalah <span><span class=MathJax_Preview>\hat \sigma_{12}=-0.039</span><script type=math/tex>\hat \sigma_{12}=-0.039</script></span> dan korelasi antara dua atribut tersebut adalah $$ \hat { \rho } _ { 12 } = \frac { - 0.039 } { \sqrt { 0.681 \cdot 0.187 } } = - 0.109 $$ Lalu, ada korelasi yang sangat lemah antara dua atribut tersebut</p> <p>Total variansi sampel dinyatakan dengan $$ \operatorname { tr } ( \hat { \Sigma } ) = 0.681 + 0.187 = 0.868 $$ dan variansi secara umum dinyatakan dengan $$ \hat { \Sigma } | = \operatorname { det } ( \hat { \Sigma } ) = 0.681 \cdot 0.187 - ( - 0.039 ) ^ { 2 } = 0.126 $$</p> <h4 id=analisa-multivariate>Analisa Multivariate<a class=headerlink href=#analisa-multivariate title="Permanent link">&para;</a></h4> <p>Dalam analisa multivariate, kita melihat atribut numerik dengan <span><span class=MathJax_Preview>d</span><script type=math/tex>d</script></span> dimensi <span><span class=MathJax_Preview>X_1,X_2,...X_d</span><script type=math/tex>X_1,X_2,...X_d</script></span>. Data dinyatakan degan matrik <span><span class=MathJax_Preview>n\times d</span><script type=math/tex>n\times d</script></span> seperti berikut $$ D = \left( \begin{array} { c c c c } { X _ { 1 } } &amp; { X _ { 2 } } &amp; { \cdots } &amp; { X _ { d } } \ \hline x _ { 11 } &amp; { x _ { 12 } } &amp; { \cdots } &amp; { x _ { 1 d } } \ { x _ { 21 } } &amp; { x _ { 22 } } &amp; { \cdots } &amp; { x _ { 2 d } } \ { \vdots } &amp; { \vdots } &amp; { \ddots } &amp; { \vdots } \ { x _ { n 1 } } &amp; { x _ { n 2 } } &amp; { \cdots } &amp; { x _ { n d } } \end{array} \right) $$</p> <p>Jika dilihat dari baris data memiliki <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> objek atatu vektor dalam <span><span class=MathJax_Preview>d</span><script type=math/tex>d</script></span> ruang dimensi atribut $$ x _ { i } = ( x _ { i 1 } , x _ { i 2 } , \ldots , x _ { i d } ) ^ { T } \in \mathbb R ^ { d } $$ Jika dilihat dari sudut pandang kolom, data diangga sebagai <span><span class=MathJax_Preview>d</span><script type=math/tex>d</script></span> objek atau vektor dalam <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> dimensi ruang dengan titik-titik data $$ X _ { j } = ( x _ { 1 j } , x _ { 2 j } , \ldots , x _ { n j } ) ^ { T } \in R ^ { n } $$</p> <p>Jika dilihat dari sudut pandang probabilitas, <span><span class=MathJax_Preview>d</span><script type=math/tex>d</script></span> atribut dimodelkan dengan variabel acak vektor <span><span class=MathJax_Preview>X=(X_1,X_2,...X_d)^T</span><script type=math/tex>X=(X_1,X_2,...X_d)^T</script></span> dan titik titik <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> dianggap sebagai sampel acak yang diperoleh dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, atribut atribut tersebut independent and identfically distributed dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> (i.i.d <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>)</p> <h5 id=mean_2><strong>Mean</strong><a class=headerlink href=#mean_2 title="Permanent link">&para;</a></h5> <p>Generalisasi persamaan (2.18) rata-rata vektor multivariate diperoleh dari masing-masing atribut yang dinyatakan dengan $$ \mu = E [ X ] = \left( \begin{array} { c } { E [ X _ { 1 } ] } \ { E [ X _ { 2 } ] } \ { \vdots } \ { E [ X _ { d } ] } \end{array} \right) = \left( \begin{array} { c } { \mu _ { 1 } } \ { \mu _ { 2 } } \ { \vdots } \ { \mu _ { d } } \end{array} \right) $$ Generalisasi persamaan (2.19) rata-rata sampel dinyatakan dengan $$ \hat { \mu } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i } $$</p> <h5 id=matrik-kovarian_1><strong>Matrik Kovarian</strong><a class=headerlink href=#matrik-kovarian_1 title="Permanent link">&para;</a></h5> <p>Generalisasi persamaan (2.26) untuk <span><span class=MathJax_Preview>d</span><script type=math/tex>d</script></span> dimensi, kovarian multicovariate di dinyatakan dengan matrik kovarian simetris $ d\times d $yang menyatakan kovarian untuk setiap pasangan atribut $$ \Sigma = E [ ( X - \mu ) ( X - \mu ) ^ { T } ] = \left( \begin{array} { c c c c } { \sigma _ { 1 } ^ { 2 } } &amp; { \sigma _ { 12 } } &amp; { \cdots } &amp; { \sigma _ { 1 d } } \ { \sigma _ { 21 } } &amp; { \sigma _ { 2 } ^ { 2 } } &amp; { \cdots } &amp; { \sigma _ { 2 d } } \ { \cdots } &amp; { \cdots } &amp; { \cdots } &amp; { \cdots } \ { \sigma _ { d 1 } } &amp; { \sigma _ { d 2 } } &amp; { \cdots } &amp; { \sigma _ { d } ^ { 2 } } \end{array} \right) $$ Elemen diagonal $\sigma_i^2 $ menyatakan variansi atribut <span><span class=MathJax_Preview>X_i</span><script type=math/tex>X_i</script></span>, dimana elemen-elemen bukan diagonal <span><span class=MathJax_Preview>\sigma_{ij} = \sigma_{ji}</span><script type=math/tex>\sigma_{ij} = \sigma_{ji}</script></span> menyatakan kovarian antara atribut pasangan <span><span class=MathJax_Preview>X_i</span><script type=math/tex>X_i</script></span> dan <span><span class=MathJax_Preview>X_j</span><script type=math/tex>X_j</script></span>. Matrik kovarian adalah positif semidefinite</p> <p><strong>Contoh Rata-rata sample dan matrik covarian.</strong></p> <p>Perhatikan semua atribut numerik untuk data iris, namanya sepal length, petal length, dan petal width. Rata rata multivarean dinyatakan dengan </p> <div> <div class=MathJax_Preview> \hat { \mu } = ( 5.843 \quad 3.054 \quad 3.759 \quad 1.199 ) ^ { T } $$ dan matrik covarian nya adalah $$ \hat { \Sigma } = \left( \begin{array} { r r r r } { 0.681 } &amp; { - 0.039 } &amp; { 1.265 } &amp; { 0.513 } \\ { - 0.039 } &amp; { 0.187 } &amp; { - 0.320 } &amp; { - 0.117 } \\ { 1.265 } &amp; { - 0.320 } &amp; { 3.092 } &amp; { 1.288 } \\ { 0.513 } &amp; { - 0.117 } &amp; { 1.288 } &amp; { 0.579 } \end{array} \right) $$ Jumlah variansi adalah $$ \operatorname { var } ( D ) = \operatorname { tr } ( \hat { \Sigma } ) = 0.681 + 0.187 + 3.092 + 0.579 = 4.539 </div> <script type="math/tex; mode=display">
\hat { \mu } = ( 5.843 \quad 3.054 \quad 3.759 \quad 1.199 ) ^ { T }
$$
dan matrik covarian nya adalah 
$$
\hat { \Sigma } = \left( \begin{array} { r r r r } { 0.681 } & { - 0.039 } & { 1.265 } & { 0.513 } \\ { - 0.039 } & { 0.187 } & { - 0.320 } & { - 0.117 } \\ { 1.265 } & { - 0.320 } & { 3.092 } & { 1.288 } \\ { 0.513 } & { - 0.117 } & { 1.288 } & { 0.579 } \end{array} \right)
$$
Jumlah variansi adalah  
$$
\operatorname { var } ( D ) = \operatorname { tr } ( \hat { \Sigma } ) = 0.681 + 0.187 + 3.092 + 0.579 = 4.539
</script> </div> <p><strong>Contoh Perkalian dalam dan perkalian luar</strong>. Untuk mengdeskripsikan komputasi perkalian dalam dan perkalian luar dari matrik covarian, perhatikan data 2-dimensi $$ D = \left( \begin{array} { l l } { A _ { 1 } } &amp; { A _ { 2 } } \ \hline 1 &amp; { 0.8 } \ { 5 } &amp; { 2.4 } \ { 9 } &amp; { 5.5 } \end{array} \right) $$</p> <p>Rata-rata vektor adalah sebagai berikut $$ \hat { \mu } = \left( \begin{array} { l } { \hat { \mu } _ { 1 } } \ { \hat { \mu } _ { 2 } } \end{array} \right) = \left( \begin{array} { l } { 15 / 3 } \ { 8.7 / 3 } \end{array} \right) = \left( \begin{array} { c } { 5 } \ { 2.9 } \end{array} \right) $$ dan matrik data terpusat dinyatakan $$ Z = D - 1 \cdot \mu ^ { T } = \left( \begin{array} { l l } { 1 } &amp; { 0.8 } \ { 5 } &amp; { 2.4 } \ { 9 } &amp; { 5.5 } \end{array} \right) - \left( \begin{array} { l } { 1 } \ { 1 } \ { 1 } \end{array} \right) \left( \begin{array} { l l } { 5 } &amp; { 2.9 } \end{array} \right) = \left( \begin{array} { r r } { - 4 } &amp; { - 2.1 } \ { 0 } &amp; { - 0.5 } \ { 4 } &amp; { 2.6 } \end{array} \right) $$ Pendekatan perkalian dalam [pers. 2.30] untuk menghitung matrik kovarian adalah $$ \left. \begin{array}{l}{ \hat { \Sigma } = \frac { 1 } { n } Z ^ { T } Z = \frac { 1 } { 3 } \left( \begin{array} { c c c } { - 4 } &amp; { 0 } &amp; { 4 } \ { - 2.1 } &amp; { - 0.5 } &amp; { 2.6 } \end{array} \right) \cdot \left( \begin{array} { c c } { - 4 } &amp; { - 2.1 } \ { 0 } &amp; { - 0.5 } \ { 4 } &amp; { 2.6 } \end{array} \right) }\{ = \frac { 1 } { 3 } \left( \begin{array} { c c } { 32 } &amp; { 18.8 } \ { 18.8 } &amp; { 11.42 } \end{array} \right) = \left( \begin{array} { c c } { 10.67 } &amp; { 6.27 } \ { 6.27 } &amp; { 3.81 } \end{array} \right) }\end{array} \right. $$ Pendekatan lain yaitu dengan perkalian luar [pers. 2.31] dibyatakan dengan $$ \hat { \Sigma } = \frac { 1 } { n } \sum _ { j = 1 } ^ { n } z _ { i } \cdot z _ { i } ^ { T } $$</p> <div> <div class=MathJax_Preview> = \frac { 1 } { 3 } \left [ \left( \begin{array} { c } { - 4 } \\ { - 2.1 } \end{array} \right) \cdot \left( \begin{array} { c c } { - 4 } &amp; { - 2.1 } \end{array} \right) + \left( \begin{array} { r r } { 0 } \\ { - 0.5 } \end{array} \right) \cdot \left( \begin{array} { c c } { 0 } &amp; { - 0.5 } \end{array} \right) + \left( \begin{array} { c } { 4 } \\ { 2.6 } \end{array} \right) \cdot \left( \begin{array} { c c } { 4 } &amp; { 2.6 } \end{array} \right)\right ] </div> <script type="math/tex; mode=display">
= \frac { 1 } { 3 } \left [ \left( \begin{array} { c } { - 4 } \\ { - 2.1 } \end{array} \right) \cdot \left( \begin{array} { c c } { - 4 } & { - 2.1 } \end{array} \right) + \left( \begin{array} { r r } { 0 } \\ { - 0.5 } \end{array} \right) \cdot \left( \begin{array} { c c } { 0 } & { - 0.5 } \end{array} \right) + \left( \begin{array} { c } { 4 } \\ { 2.6 } \end{array} \right) \cdot \left( \begin{array} { c c } { 4 } & { 2.6 } \end{array} \right)\right ]
</script> </div> <div> <div class=MathJax_Preview> \left. \begin{array} { l } { = \frac { 1 } { 3 } [ \left( \begin{array} { c c } { 16.0 } &amp; { 8.4 } \\ { 8.4 } &amp; { 4.41 } \end{array} \right) + \left( \begin{array} { c c } { 0.0 } &amp; { 0.0 } \\ { 0.0 } &amp; { 0.25 } \end{array} \right) + \left( \begin{array} { c c } { 16.0 } &amp; { 10.4 } \\ { 10.4 } &amp; { 6.76 } \end{array} \right) ] } \\ { = \frac { 1 } { 3 } \left( \begin{array} { c c } { 32.0 } &amp; { 18.8 } \\ { 18.8 } &amp; { 11.42 } \end{array} \right) = \left( \begin{array} { c c } { 10.67 } &amp; { 6.27 } \\ { 6.27 } &amp; { 3.81 } \end{array} \right) } \end{array} \right. </div> <script type="math/tex; mode=display">
\left. \begin{array} { l } { = \frac { 1 } { 3 } [ \left( \begin{array} { c c } { 16.0 } & { 8.4 } \\ { 8.4 } & { 4.41 } \end{array} \right) + \left( \begin{array} { c c } { 0.0 } & { 0.0 } \\ { 0.0 } & { 0.25 } \end{array} \right) + \left( \begin{array} { c c } { 16.0 } & { 10.4 } \\ { 10.4 } & { 6.76 } \end{array} \right) ] } \\ { = \frac { 1 } { 3 } \left( \begin{array} { c c } { 32.0 } & { 18.8 } \\ { 18.8 } & { 11.42 } \end{array} \right) = \left( \begin{array} { c c } { 10.67 } & { 6.27 } \\ { 6.27 } & { 3.81 } \end{array} \right) } \end{array} \right.
</script> </div> <p>dimana data terpusat <span><span class=MathJax_Preview>z_i</span><script type=math/tex>z_i</script></span> adalah baris dari <span><span class=MathJax_Preview>Z</span><script type=math/tex>Z</script></span></p> <h4 id=atribut-kategorikal><strong>Atribut Kategorikal</strong><a class=headerlink href=#atribut-kategorikal title="Permanent link">&para;</a></h4> <p>Kita asumsikan bahwa data terdiri dari satu atribut <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. Domain dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> terdiri dari <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> nilai simbolis <span><span class=MathJax_Preview>dom(X)={a_1,a_2,...a_m}</span><script type=math/tex>dom(X)={a_1,a_2,...a_m}</script></span>. Data <span><span class=MathJax_Preview>D</span><script type=math/tex>D</script></span> adalah <span><span class=MathJax_Preview>n\times 1</span><script type=math/tex>n\times 1</script></span> matrik data simbolis yang dinyatakan dengan $$ D = \left( \begin{array} { c } { X } \ { x _ { 1 } } \ { x _ { 2 } } \ { \vdots } \ { x _ { n } } \end{array} \right) $$ dimana setiap nilai <span><span class=MathJax_Preview>x_i \in dom(X)</span><script type=math/tex>x_i \in dom(X)</script></span> </p> <h5 id=variabel-bernouli>Variabel Bernouli<a class=headerlink href=#variabel-bernouli title="Permanent link">&para;</a></h5> <p>Marilah kita lihat kasus ketika atribut kategorikal <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> memililik domain $ {a_1,a_2}$ dengan <span><span class=MathJax_Preview>m=2</span><script type=math/tex>m=2</script></span>. Kita dapat memodelkan <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> sebagai variabel acak Bernouli, yang didasarkan pada dua nilai berbeda yaitu 1 dan 0, sesuai dengan pemetaan $$ X ( v ) = \left{ \begin{array} { l l } { 1 } &amp; { \text { if } v = a _ { 1 } } \ { 0 } &amp; { \text { if } v = a _ { 2 } } \end{array} \right. $$ Fungsi massa probabilitas (PMF) dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan $$ P ( X = x ) = f ( x ) = \left{ \begin{array} { l l } { p _ { 1 } } &amp; { \text { if } x = 1 } \ { p _ { 0 } } &amp; { \text { if } x = 0 } \end{array} \right. $$ dimana <span><span class=MathJax_Preview>p_1</span><script type=math/tex>p_1</script></span> dan <span><span class=MathJax_Preview>p_0</span><script type=math/tex>p_0</script></span> adalah parameter distribusi, yang harus memenuhi kondisi $$ p_1+p_0=1 $$ Karena hanya ada satu parameter bebas, biasanya menotasikan <span><span class=MathJax_Preview>p_1=p</span><script type=math/tex>p_1=p</script></span> maka <span><span class=MathJax_Preview>p_0=1-p</span><script type=math/tex>p_0=1-p</script></span>. Fungsi Massa Probabilitas dari variabel acak Bernouli <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dapat kemudian ditulis dengan $$ P ( X = x ) = f ( x ) = p ^ { x } ( 1 - p ) ^ { 1 - x } $$ Kita dapat melihat bahwa <span><span class=MathJax_Preview>P ( X = 1 ) = p ^ { 1 } ( 1 - p ) ^ { 0 } = p \text { and } P ( X = 0 ) = p ^ { 0 } ( 1 - p ) ^ { 1 } = 1 - p</span><script type=math/tex>P ( X = 1 ) = p ^ { 1 } ( 1 - p ) ^ { 0 } = p \text { and } P ( X = 0 ) = p ^ { 0 } ( 1 - p ) ^ { 1 } = 1 - p</script></span> seperti yand diharapkan</p> <p>Mean dan Variansi</p> <p>Nilai harapan dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan $$ \mu = E [ X ] = 1 \cdot p + 0 \cdot ( 1 - p ) = p $$ dan variansi dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan $$ \left. \begin{array}{l}{ \sigma ^ { 2 } = \operatorname { var } ( X ) = E [ X ^ { 2 } ] - ( E [ X ] ) ^ { 2 } }\ \hspace{7mm}= ( 1 ^ { 2 } \cdot p + 0 ^ { 2 } \cdot ( 1 - p ) ) - p ^ { 2 } = p - p ^ { 2 } = p ( 1 - p ) \\end{array} \right. $$</p> <p>Rata-rata sampel dan Variansi</p> <p>Untuk mengestimasi parameter dari variabel Bernouli <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, kita asumsikan bahwa setiap simbol dipetakan ke nilai biner. Sehingga, sekumpulan nilai <span><span class=MathJax_Preview>{x_1,x_2,...x_n}</span><script type=math/tex>{x_1,x_2,...x_n}</script></span> diasumsikan menjadi sampel acak yang diperoleh dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> (yaitu setiap $ x_i$ adalah IID dengan <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>.</p> <p>Rata-rata sampel dinyatakan dengan $$ \hat { \mu } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } x _ { i } = \frac { n _ { 1 } } { n } = \hat { p } $$ dimana <span><span class=MathJax_Preview>n_1</span><script type=math/tex>n_1</script></span> adalah banyaknya titik dengan <span><span class=MathJax_Preview>x_1=1</span><script type=math/tex>x_1=1</script></span> dalam sampel acak (sama dengan banyak kejadian dari simbol <span><span class=MathJax_Preview>a_1</span><script type=math/tex>a_1</script></span>)</p> <p>Misal <span><span class=MathJax_Preview>n_0=n-n_1</span><script type=math/tex>n_0=n-n_1</script></span> menyatakan banyak titik dengan <span><span class=MathJax_Preview>x_i=0</span><script type=math/tex>x_i=0</script></span> dalam sampel acak. Variansi sample dinyatakan dengan $$ \left. \begin{array}{l}{ \hat { \sigma } ^ { 2 } = \frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( x _ { i } - \hat { \mu } ) ^ { 2 } }\ \hspace{7mm}{ = \frac { n _ { 1 } } { n } ( 1 - \hat { p } ) ^ { 2 } + \frac { n - n _ { 1 } } { n } ( - \hat { p } ) ^ { 2 } }\\hspace{7mm}{ = \hat { p } ( 1 - \hat { p } ) ^ { 2 } + ( 1 - \hat { p } ) \hat { p } ^ { 2 } }\\hspace{7mm}{ = \hat { p } ( 1 - \hat { p } ) ( 1 - \hat { p } + \hat { p } ) }\\hspace{7mm}{ = \hat { p } ( 1 - \hat { p } ) }\end{array} \right. $$</p> <p>Variansi sampel dapat juga diperoleh langsung dari persamaan(3.1) dengan mensubsitusikan <span><span class=MathJax_Preview>\hat p</span><script type=math/tex>\hat p</script></span> untuk <span><span class=MathJax_Preview>p</span><script type=math/tex>p</script></span> .</p> <p><strong>Contoh</strong></p> <p>Perhatikan atribut sepal length (<span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>) untuk dataset iris dalam tabel 1.1. Marilah kita definisikan bunga iris dengan <em>Long</em> jika bunga itu sepal length dalam range <span><span class=MathJax_Preview>[7, \infty ]</span><script type=math/tex>[7,  \infty ]</script></span>, dan <em>short</em> jika sepal length dalam range <span><span class=MathJax_Preview>[-\infty,7]</span><script type=math/tex>[-\infty,7]</script></span>. Kemudian <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> dapat dinyatakan dengan atribut kategorikan dengan domain {Long,Short}. Dari sampel yang diamati ukuran <span><span class=MathJax_Preview>n=150</span><script type=math/tex>n=150</script></span>, kita menemukan 13 iris long. Rata-rata sampel dari <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> adalah $$ \hat { \mu } = \hat { p } = 13 / 150 = 0.087 $$ dan variansinya adalah $$ \hat { \sigma } ^ { 2 } = \hat { p } ( 1 - \hat { p } ) = 0.087 ( 1 - 0.087 ) = 0.087 \cdot 0.913 = 0.079 $$</p> <h5 id=ditribusi-binomial-banyaknya-kejadian><strong>Ditribusi binomial : banyaknya kejadian</strong><a class=headerlink href=#ditribusi-binomial-banyaknya-kejadian title="Permanent link">&para;</a></h5> <p>Diberikan variabel Bernoulli <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>, misal <span><span class=MathJax_Preview>\{x_1,x_2,...x_n\}</span><script type=math/tex>\{x_1,x_2,...x_n\}</script></span> menyatakan sampel acak dari ukuran <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> yang diperoleh dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span>. Misal <span><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span> adalah variabel acak yang menyatakan numlah kejadi dari simbol <span><span class=MathJax_Preview>a_1</span><script type=math/tex>a_1</script></span>(nilai <span><span class=MathJax_Preview>X=1</span><script type=math/tex>X=1</script></span>) dalam sampe. N adalah distribusi binomial yang dinyatakan dengan $$ f ( N = n _ { 1 } | n , p ) = \left( \begin{array} { l } { n } \ { n _ { 1 } } \end{array} \right) p ^ { n _ { 1 } } ( 1 - p ) ^ { n - n _ { 1 } } $$ Dalam kenyataannya, <span><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span> adalah jumlah dari <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> variabel acak Bernoulli <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> yang saling bebas dan (IID) dengan <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> yaitu <span><span class=MathJax_Preview>N=\sum_{i=1}^n x_i</span><script type=math/tex>N=\sum_{i=1}^n x_i</script></span> . Dengan liniearitas dari ekpektasi, mean atau jumlah harapan dari kejadian simbol <span><span class=MathJax_Preview>a_i</span><script type=math/tex>a_i</script></span> dinyatakan dengan $$ \mu _ { N } = E [ N ] = E \left[ \sum _ { i = 1 } ^ { n } x _ { i } \right] = \sum _ { i = 1 } ^ { n } E [ x _ { i } ] = \sum _ { i = 1 } ^ { n } p = n p $$ Karena <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> adalah semuanya saling bebas, variansi dari <span><span class=MathJax_Preview>N</span><script type=math/tex>N</script></span> dinyatakan dengan $$ \sigma _ { N } ^ { 2 } = \operatorname { var } ( N ) = \sum _ { i = 1 } ^ { n } \operatorname { var } ( x _ { i } ) = \sum _ { i = 1 } ^ { n } p ( 1 - p ) = n p ( 1 - p ) $$ Contoh 3.2. Dengan meneruskan contoh 3.1, kita dapat menggunakan parameter yang telah diestimasi <span><span class=MathJax_Preview>\hat p=0.087</span><script type=math/tex>\hat p=0.087</script></span> untuk menghitung banyaknya kejadian yang diharapkan N long dari sepal length. distribusi binomial Iris $$ E [ N ] = n \hat { p } = 150 \cdot 0.087 = 13 $$</p> <p>Dalam kasus ini, karena <span><span class=MathJax_Preview>p</span><script type=math/tex>p</script></span> dihitung dari sample melalui <span><span class=MathJax_Preview>\hat p</span><script type=math/tex>\hat p</script></span>, tidak mengherankan bahwa jumlah kejadian diharapkan dari Long Iris sama dengan kejadian yang sebenarnya. Akan tetapi yang lebih menarik adalah kita dapat menghitung variansi jumlah kejadian $$ \operatorname { var } ( N ) = n \hat { p } ( 1 - \hat { p } ) = 150 \cdot 0.079 = 11.9 $$</p> <p>Meningkatnya ukuran sample, distribusi binomial seperti yang diberikan dapalam persamaan 3.3 cenderung ke distribusi normal dengan <span><span class=MathJax_Preview>\mu=13</span><script type=math/tex>\mu=13</script></span> dan <span><span class=MathJax_Preview>\sigma=\sqrt{11.9}=3.45</span><script type=math/tex>\sigma=\sqrt{11.9}=3.45</script></span>. Sehingga dengan kepercaan lebih besar dari 95%, kita dapat mengklam bahwa jumlah kejadian dari <span><span class=MathJax_Preview>a_i</span><script type=math/tex>a_i</script></span> akan terletak dalam rentang <span><span class=MathJax_Preview>\mu \pm 2 \sigma = [ 9.55,16.45 ]</span><script type=math/tex>\mu \pm 2 \sigma = [ 9.55,16.45 ]</script></span> yang mengikuti dari fakta bahwa untuk distribusi normal 95,45% dari massa probabilitas terletak dalam dua standar deviasi dari rata-rata.</p> <h5 id=variable-multivariate-bernoulli>Variable multivariate Bernoulli<a class=headerlink href=#variable-multivariate-bernoulli title="Permanent link">&para;</a></h5> <p>Sekarang kita memandang kasus umum ketika <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> adalah atribut kategorical dengan domain <span><span class=MathJax_Preview>\{a_1,a_2,...a_m\}</span><script type=math/tex>\{a_1,a_2,...a_m\}</script></span>. Kita dapat memodelkan <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> sebagai variabel acak Bernoulli <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> -dimensi <span><span class=MathJax_Preview>X = ( A _ { 1 } , A _ { 2 } , \ldots , A _ { m } ) ^ { T }</span><script type=math/tex>X = ( A _ { 1 } , A _ { 2 } , \ldots , A _ { m } ) ^ { T }</script></span> dimana setiap <span><span class=MathJax_Preview>A_i</span><script type=math/tex>A_i</script></span> adalah variabel Bernoulli dengan parameter <span><span class=MathJax_Preview>p_i</span><script type=math/tex>p_i</script></span> yang menotasikan probabilitas dari pengamatan simbol <span><span class=MathJax_Preview>a_i</span><script type=math/tex>a_i</script></span>. Akan tetapi karena <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dapat mengasumsikan hanya satu dari nilai simbolik pada suatu waktum jika <span><span class=MathJax_Preview>X=a_i</span><script type=math/tex>X=a_i</script></span> maka <span><span class=MathJax_Preview>A_i=1</span><script type=math/tex>A_i=1</script></span> dan <span><span class=MathJax_Preview>A_j=0</span><script type=math/tex>A_j=0</script></span> untuk semua <span><span class=MathJax_Preview>j \neq i</span><script type=math/tex>j \neq i</script></span>. Variabel acak <span><span class=MathJax_Preview>X \in {0,1}^m</span><script type=math/tex>X \in {0,1}^m</script></span>, dan jika <span><span class=MathJax_Preview>X=a_i</span><script type=math/tex>X=a_i</script></span>, maka <span><span class=MathJax_Preview>X=e_i</span><script type=math/tex>X=e_i</script></span>, dimana <span><span class=MathJax_Preview>e_i</span><script type=math/tex>e_i</script></span> adalah standar vektor basis ke i, <span><span class=MathJax_Preview>e_i\in\mathbb R^m</span><script type=math/tex>e_i\in\mathbb R^m</script></span> yang dinyatakan dengan $$ e _ { i } = ( \overbrace { 0 , \ldots , 0 } ^ { i - 1 } , 1 , \overbrace { 0 , \ldots , 0 } ^ { m - i } ) ^ { T } $$ Pada <span><span class=MathJax_Preview>e_i</span><script type=math/tex>e_i</script></span> hanya elemen ke i adalah 1 (<span><span class=MathJax_Preview>e_{ii}=1</span><script type=math/tex>e_{ii}=1</script></span>) , sedangkan semua elemen yang lain adalah nol, (<span><span class=MathJax_Preview>e_{ij}=0, \forall j \neq i</span><script type=math/tex>e_{ij}=0, \forall j \neq i</script></span>).</p> <p>Disini, definis yang lebih tepat dari variabel Bernoulli multivariate , yaitu generalisasi dari variabel Bernoullii dari dua hasil ke <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> hasil. Kita kemudian memodelkan atribut kategorical <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> sebagai variabel Bernoulli multivariate <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> didefinisikan dengan $$ X ( v ) = e _ { i } \text { if } v = a _ { i } $$</p> <p>Rentang dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> terdiri dari <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> nilai vektor berbeda <span><span class=MathJax_Preview>\{e_1,e_2,...e_m\}</span><script type=math/tex>\{e_1,e_2,...e_m\}</script></span> dengan fungsi massa probabilitas dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dinyatakan dengan $$ P ( X = e _ { i } ) = f ( e _ { i } ) = p _ { i } $$ dimana <span><span class=MathJax_Preview>p_i</span><script type=math/tex>p_i</script></span> adalah probabilitas dari nilai pengamatan <span><span class=MathJax_Preview>a_i</span><script type=math/tex>a_i</script></span>. Parameter ini harus memenuhi kondisi $$ \sum _ { i = 1 } ^ { m } p _ { i } = 1 $$ Fungsi massa prababilitas dapat ditulis secara utuh sebagai berikut $$ P ( X = e _ { i } ) = f ( e _ { i } ) = \prod _ { j = 1 } ^ { m } p _ { j } ^ { e _ { i j } }Ka $$ Kareana <span><span class=MathJax_Preview>e_ii=1</span><script type=math/tex>e_ii=1</script></span> dan <span><span class=MathJax_Preview>e_ij=0</span><script type=math/tex>e_ij=0</script></span> funtuk $ j\neq i$, kita dapat melihat bahwa, seperti yang diharapkan, kita miliki $$ f ( e _ { i } ) = \prod _ { j=1 } ^ { m } p _ { j } ^ { e _ { i j } } = p _ { 1 } ^ { e _ { i 0 } } \times \cdots p _ { i } ^ { e _ { i i } } \cdots \times p _ { m } ^ { e _ { i m } } = p _ { 1 } ^ { 0 } \times \cdots p _ { i } ^ { 1 } \cdots \times p _ { m } ^ { 0 } = p _ { i } $$</p> <div> <div class=MathJax_Preview> \left. \begin{array} { | l | l | l | } \hline \text { Bins } &amp; { { \text { Domain } } } &amp; { { \text { Counts } } } \\ \hline [ 4.3,5.2 ] &amp; { \text { Very Short } ( a _ { 1 } ) } &amp; { n _ { 1 } = 45 } \\ { ( 5.2,6.1 ] } &amp; { \text { Short } ( a _ { 2 } ) } &amp; { n _ { 2 } = 50 } \\ { ( 6.1,7.0 ] } &amp; { \text { Long } ( a _ { 3 } ) } &amp; { n _ { 3 } = 43 } \\ { ( 7.0,7.9 ] } &amp; { \text { Very Long } ( a _ { 4 } ) } &amp; { n _ { 4 } = 12 } \\ \hline \end{array} \right. </div> <script type="math/tex; mode=display">
\left. \begin{array} { | l | l | l | } \hline \text { Bins } & {  { \text { Domain } } } & {  { \text { Counts } } } \\ \hline [ 4.3,5.2 ] & { \text { Very Short } ( a _ { 1 } ) } & { n _ { 1 } = 45 } \\ { ( 5.2,6.1 ] } & { \text { Short } ( a _ { 2 } ) } & { n _ { 2 } = 50 } \\ { ( 6.1,7.0 ] } & { \text { Long } ( a _ { 3 } ) } & { n _ { 3 } = 43 } \\ { ( 7.0,7.9 ] } & { \text { Very Long } ( a _ { 4 } ) } & { n _ { 4 } = 12 } \\ \hline \end{array} \right.
</script> </div> <p><strong>Contoh :</strong> Marilah kita lihat atribut sepal length (<span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span>) untuk data Iris seperti yang ditunjukkan dalam tabel 1.2. Kita membagi sepal length kedalam empat interval yang sama, dan memberikan nama untuk setiap interval seperti yang diunjukkan dalam tabel 3.1. Kita lihat <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> sebagai atribut kategorical dengan domain $$ {a _ { 2 } = \text { VeryShort, } a _ { 2 } = \text { Short, } a _ { 3 } = \operatorname { Long } , a _ { 4 } = \operatorname{Very Long}} $$</p> <p>Kita memodelkan atribut kategorical <span><span class=MathJax_Preview>X_1</span><script type=math/tex>X_1</script></span> sebagai variabel <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> Bernoulli multivariate, didefinisikan dengan $$ X ( v ) = \left{ \begin{array} { l l } { e _ { 1 } = ( 1,0,0,0 ) } &amp; { \text { jika } v = a _ { 1 } } \ { e _ { 2 } = ( 0,1,0,0 ) } &amp; { \text { jika } v = a _ { 2 } } \ { e _ { 3 } = ( 0,0,1,0 ) } &amp; { \text { jika } v = a _ { 3 } } \ { e _ { 4 } = ( 0,0,0,1 ) } &amp; { \text { jika } v = a _ { 4 } } \end{array} \right. $$ Misalkan, simbol <span><span class=MathJax_Preview>x_1=Short=a_2</span><script type=math/tex>x_1=Short=a_2</script></span> dinyatakan dengan <span><span class=MathJax_Preview>(0,1,0,0)^T=e_2</span><script type=math/tex>(0,1,0,0)^T=e_2</script></span></p> <p><strong>Mean</strong></p> <p>Mean atau nilai harapan dari <span><span class=MathJax_Preview>X</span><script type=math/tex>X</script></span> dapat diperoleh dengan $$ \mu = E [ X ] = \sum _ { i = 1 } ^ { m } e _ { i } f ( e _ { i } ) = \sum _ { i = 1 } ^ { m } e _ { i } p _ { i } = \left( \begin{array} { l } { 1 } \ { 0 } \ { \vdots } \ { 0 } \end{array} \right) p _ { 1 } + \cdots + \left( \begin{array} { l } { 0 } \ { 0 } \ { \vdots } \ { 1 } \end{array} \right) p _ { m } = \left( \begin{array} { c } { p _ { 1 } } \ { p _ { 2 } } \ { \vdots } \ { p _ { m } } \end{array} \right) = p $$</p> <h3 id=mengukur-jarak-data>Mengukur Jarak Data<a class=headerlink href=#mengukur-jarak-data title="Permanent link">&para;</a></h3> <h4 id=mengukur-jarak-tipe-numerik>Mengukur Jarak Tipe Numerik<a class=headerlink href=#mengukur-jarak-tipe-numerik title="Permanent link">&para;</a></h4> <p>Salah satu tantangan dalam era ini dengan datatabase yang memiliki banyak tipe data. Mngukur jarak adalah komponen utama dalam algoritma clustering berbasis jarak. Alogritma seperit Algoritma Partisioning misal K-Mean, K-medoidm dan fuzzy c-mean dan rough clustering bergantung pada jarak untuk melakukan pengelompokkan</p> <p>Sebelum menjelaskan tentang beberapa macam ukuran jarak, kita mendefinisikan terlebih dahulu yaiut <span><span class=MathJax_Preview>v_1, v_2</span><script type=math/tex>v_1, v_2</script></span> menyatakandua vektor yang menyatakan <span><span class=MathJax_Preview>v_1 = {x_1, x_2, . . ., x_n}, v_2 ={y_1, y_2, . . ., y_n},</span><script type=math/tex>v_1 = {x_1, x_2, . . ., x_n}, v_2 ={y_1, y_2, . . ., y_n},</script></span> dimana <span><span class=MathJax_Preview>x_i, y_i</span><script type=math/tex>x_i, y_i</script></span> disebut attribut. Ada beberapa ukuran similaritas datau ukuran jarak, diantaranya<sup id=fnref:2><a class=footnote-ref href=#fn:2>2</a></sup></p> <h5 id=minkowski-distance><em>Minkowski Distance</em><a class=headerlink href=#minkowski-distance title="Permanent link">&para;</a></h5> <p>Kelompk Minkowski diantaranya adalah Euclidean distance dan Manhattan distance, yang menjadi kasus khusus dari Minkowski distance. Minkowski distance dinyatakan dengan</p> <div> <div class=MathJax_Preview> d _ { \operatorname { min } } = ( \ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m } ) ^ { \frac { 1 } { m } } , m \geq 1 </div> <script type="math/tex; mode=display"> d _ { \operatorname { min } } = ( \ sum _ { i = 1 } ^ { n } | x _ { i } - y _ { i } | ^ { m }  ) ^ { \frac { 1 } { m } } , m \geq 1 </script> </div> <p>diman <span><span class=MathJax_Preview>m</span><script type=math/tex>m</script></span> adalah bilangan riel positif dan <span><span class=MathJax_Preview>x_i</span><script type=math/tex>x_i</script></span> dan $ y_i$ adalah dua vektor dalam runang dimensi <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> Implementasi ukuran jarak Minkowski pada model clustering data atribut dilakukan normalisasi untuk menghindari dominasi dari atribut yang memiliki skala data besar.</p> <h5 id=manhattan-distance><em>Manhattan distance</em><a class=headerlink href=#manhattan-distance title="Permanent link">&para;</a></h5> <p>Manhattan distance adalah kasus khsusu dari jarak Minkowski distance pada m = 1. Seperti Minkowski Distance, Manhattan distance sensitif terhadap outlier. BIla ukuran ini digunakan dalam algoritma clustering , bentuk cluster adalah hyper-rectangular. Ukuran ini didefinisikan dengan </p> <div> <div class=MathJax_Preview> d _ { \operatorname { man } } = \sum _ { i = 1 } ^ { n } \left| x _ { i } - y _ { i } \right| </div> <script type="math/tex; mode=display"> d _ { \operatorname { man } } = \sum _ { i = 1 } ^ { n } \left| x _ { i } - y _ { i } \right| </script> </div> <h5 id=euclidean-distance><em>Euclidean distance</em><a class=headerlink href=#euclidean-distance title="Permanent link">&para;</a></h5> <p>Jarak yang paling terkenal yang digunakan untuk data numerik adalah jarak Euclidean. Ini adalah kasus khusus dari jarak Minkowski ketika m = 2. Jarak Euclidean berkinerja baik ketika digunakan untuk kumpulan data cluster kompak atau terisolasi . Meskipun jarak Euclidean sangat umum dalam pengelompokan, ia memiliki kelemahan: jika dua vektor data tidak memiliki nilai atribut yang sama, kemungkin memiliki jarak yang lebih kecil daripada pasangan vektor data lainnya yang mengandung nilai atribut yang sama. Masalah lain dengan jarak Euclidean sebagai fitur skala terbesar akan mendominasi yang lain. Normalisasi fitur kontinu adalah solusi untuk mengatasi kelemahan ini. </p> <h5 id=average-distance><em>Average Distance</em><a class=headerlink href=#average-distance title="Permanent link">&para;</a></h5> <p>Berkenaan dengan kekurangan dari Jarak Euclidian Distance diatas, rata rata jarak adala versi modikfikasid ari jarak Euclidian untuk memperbaiki hasil. Untuk dua titik <span><span class=MathJax_Preview>x,y</span><script type=math/tex>x,y</script></span> dalam ruang dimensi <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span>, rata-rata jarak didefinisikan dengan </p> <div> <div class=MathJax_Preview>d _ { a v e } = \left ( \frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \right) ^ { \frac { 1 } { 2 } }</div> <script type="math/tex; mode=display">d _ { a v e } =  \left ( \frac { 1 } { n } \sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } \right) ^ { \frac { 1 } { 2 } }</script> </div> <h5 id=weighted-euclidean-distance><em>Weighted euclidean distance</em><a class=headerlink href=#weighted-euclidean-distance title="Permanent link">&para;</a></h5> <p>Jika berdasarkan tingkatan penting dari masing masing atribut ditentukan, maka Weighted Euclidean distance adalah modifikisasi lain dari jarak Euclidean distance yang dapat digunakan. Ukuran ini dirumuskan dengan </p> <p>$$ d _ { w e } = \left ( \sum _ { i = 1 } ^ { n } w _ { i } ( x _ { i } - y _ { i } \right) ^ { 2 } ) ^ { \frac { 1 } { 2 } } $$ dimana <span><span class=MathJax_Preview>w_i</span><script type=math/tex>w_i</script></span> adalah bobot yang diberikan pada atribut ke i.</p> <h5 id=chord-distance><em>Chord distance</em><a class=headerlink href=#chord-distance title="Permanent link">&para;</a></h5> <p>Chord distance adalah salah satu ukuran jarak modifikasi Euclidean distance untuk mengatasi kekurangan dari Euclidean distance. Ini dapat dipecahkan juga dengan menggunakan skala pengukuran yang baik. Jarak ini dapat juga dihitung dari data yang tidak dinormalisasi . Chord distance didefinisikan dengan </p> <div> <div class=MathJax_Preview> d _ { \text {chord} } = \left ( 2 - 2 \frac { \sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { \| x \| _ { 2 } \| y \| _ { 2 } } \right) ^ { \frac { 1 } { 2 } } </div> <script type="math/tex; mode=display"> d _ { \text {chord} } = \left ( 2 - 2 \frac { \sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { \| x \| _ { 2 } \| y \| _ { 2 } } \right) ^ { \frac { 1 } { 2 } } </script> </div> <p>dimana <span><span class=MathJax_Preview>\| x \|_ {2}</span><script type=math/tex>\| x \|_ {2}</script></span> adalah <span><span class=MathJax_Preview>L^{2} \text {-norm} \| x \|_{2} = \sqrt { \sum_{ i = 1 }^{ n }x_{i}^{2}}</span><script type=math/tex>L^{2} \text {-norm} \| x \|_{2} = \sqrt { \sum_{ i = 1 }^{ n }x_{i}^{2}}</script></span></p> <h5 id=mahalanobis-distance><em>Mahalanobis distance</em><a class=headerlink href=#mahalanobis-distance title="Permanent link">&para;</a></h5> <p>Mahalanobis distance berdasarkan data berbeda dengan Euclidean dan Manhattan distances yang bebas antra data dengan data yang lain. Jarak Mahalanobis yang teratur dapat digunakan untuk mengekstraksi hyperellipsoidal clusters. Jarak Mahalanobis dapat mengurangi distorsi yang disebabkan oleh korelasi linier antara fitur dengan menerapkan transformasi pemutihan ke data atau dengan menggunakan kuadrat Jarak mahalanobis. Mahalanobis distance dinyatakan dengan</p> <div> <div class=MathJax_Preview> d _ { m a h } = \sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } </div> <script type="math/tex; mode=display"> d _ { m a h } = \sqrt { ( x - y ) S ^ { - 1 } ( x - y ) ^ { T } } </script> </div> <p>diman <span><span class=MathJax_Preview>S</span><script type=math/tex>S</script></span> adalah matrik covariance data.</p> <h5 id=cosine-measure><em>Cosine measure</em><a class=headerlink href=#cosine-measure title="Permanent link">&para;</a></h5> <p>Ukuran Cosine similarity lebih banyak digunakan dalam similaritas dokumen dan dinyatakan dengan </p> <div> <div class=MathJax_Preview> Cosine(x,y)=\frac { \sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { \| x \| _ { 2 } \| y \| _ { 2 } } </div> <script type="math/tex; mode=display"> Cosine(x,y)=\frac { \sum _ { i = 1 } ^ { n } x _ { i } y _ { i } } { \| x \| _ { 2 } \| y \| _ { 2 } } </script> </div> <p>dimana <span><span class=MathJax_Preview>\|y\|_{2}</span><script type=math/tex>\|y\|_{2}</script></span> adalah Euclidean norm dari vektor <span><span class=MathJax_Preview>y=(y_{1} , y_{2} , \dots , y_{n} )</span><script type=math/tex>y=(y_{1} , y_{2} , \dots , y_{n} )</script></span> didefinisikan dengan <span><span class=MathJax_Preview>\|y\|_{2}=\sqrt{ y _ { 1 } ^ { 2 } + y _ { 2 } ^ { 2 } + \ldots + y _ { n } ^ { 2 } }</span><script type=math/tex>\|y\|_{2}=\sqrt{ y _ { 1 } ^ { 2 } + y _ { 2 } ^ { 2 } + \ldots + y _ { n } ^ { 2 } }</script></span></p> <h5 id=pearson-correlation><em>Pearson correlation</em><a class=headerlink href=#pearson-correlation title="Permanent link">&para;</a></h5> <p>Pearson correlation banyak digunakan dalam data expresi gen. Ukuran similaritas ini menghitung similaritas antara duan bentuk pola expresi gen. Pearson correlation didefinisikan dengan </p> <div> <div class=MathJax_Preview> Pearson ( x , y ) = \frac { \sum _ { i = 1 } ^ { n } ( x _ { i } - \mu _ { x } ) ( y _ { i } - \mu _ { y } ) } { \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } </div> <script type="math/tex; mode=display"> Pearson ( x , y ) = \frac { \sum _ { i = 1 } ^ { n } ( x _ { i } - \mu _ { x } ) ( y _ { i } - \mu _ { y } ) } { \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } \sqrt { \sum _ { i = 1 } ^ { n } ( x _ { i } - y _ { i } ) ^ { 2 } } } </script> </div> <p>The Pearson correlation kelemahannya adalah sensitif terhadap outlier</p> <h4 id=mengukur-jarak-atribut-binary>Mengukur Jarak Atribut Binary<a class=headerlink href=#mengukur-jarak-atribut-binary title="Permanent link">&para;</a></h4> <p>Mari kita lihat similaritas dan desimilirity untuk objek yang dijelaskan oleh atribut biner simetris atau asimetris. Aatribut biner hanya memiliki dua status: 0 dan 1 Contoh atribut perokok menggambarkan seorang pasien, misalnya, 1 menunjukkan bahwa pasien merokok, sedangkan 0 menunjukkan pasien tidak merokok. Memperlakukan atribut biner sebagai atribut numerik tidak diperkenankan. Oleh karena itu, metode khusus untuk data biner diperlukan untuk membedakan komputasi.</p> <p>Jadi, bagaimana kita bisa menghitung ketidaksamaan antara dua atribut biner? ”Satu pendekatan melibatkan penghitungan matriks ketidaksamaan dari data biner yang diberikan. Jika semua atribut biner dianggap memiliki bobot yang sama, kita memiliki tabel kontingensi <span><span class=MathJax_Preview>2 \times 2</span><script type=math/tex>2 \times 2</script></span> di mana <span><span class=MathJax_Preview>q</span><script type=math/tex>q</script></span> adalah jumlah atribut yang sama dengan 1 untuk kedua objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> dan <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span>, <span><span class=MathJax_Preview>r</span><script type=math/tex>r</script></span> adalah jumlah atribut yang sama dengan 1 untuk objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> tetapi 0 untuk objek <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span>, <span><span class=MathJax_Preview>s</span><script type=math/tex>s</script></span> adalah jumlah atribut yang sama dengan 0 untuk objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> tetapi 1 untuk objek <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span>, dan <span><span class=MathJax_Preview>t</span><script type=math/tex>t</script></span> adalah jumlah atribut yang sama dengan 0 untuk kedua objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> dan <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span>. Jumlah total atribut adalah <span><span class=MathJax_Preview>p</span><script type=math/tex>p</script></span>, di mana <span><span class=MathJax_Preview>p=q+r+s+t</span><script type=math/tex>p=q+r+s+t</script></span></p> <p>Ingatlah bahwa untuk atribut biner simetris, masing-masing nilai bobot yang sama.Dissimilarity yang didasarkan pada atribut aymmetric binary disebut symmetric binary dissimilarity. Jika objek i dan j dinyatakan sebagai atribut biner simetris, maka dissimilarity antar<span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> dan <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span> adalah</p> <div> <div class=MathJax_Preview> d ( i , j ) = \frac { r + s } { q + r + s + t } </div> <script type="math/tex; mode=display"> d ( i , j ) = \frac { r + s } { q + r + s + t } </script> </div> <p>Untuk atribut biner asimetris, kedua kondisi tersebut tidak sama pentingnya, seperti hasil positif (1) dan negatif (0) dari tes penyakit. Diberikan dua atribut biner asimetris, pencocokan keduanya 1 (kecocokan positif) kemudian dianggap lebih signifikan daripada kecocokan negatif. Ketidaksamaan berdasarkan atribut-atribut ini disebut asimetris biner dissimilarity, di mana jumlah kecocokan negatif, t, dianggap tidak penting dan dengan demikian diabaikan. Berikut perhitungannya</p> <div> <div class=MathJax_Preview> d ( i , j ) = \frac { r + s } { q + r + s } </div> <script type="math/tex; mode=display"> d ( i , j ) = \frac { r + s } { q + r + s } </script> </div> <p>Kita dapat mengukur perbedaan antara dua atribut biner berdasarkan pada disimilarity. Misalnya, biner asimetris kesamaan antara objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> dan <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span> dapat dihitung dengan</p> <div> <div class=MathJax_Preview> \operatorname { sim } ( i , j ) = \frac { q } { q + r + s } = 1 - d ( i , j ) </div> <script type="math/tex; mode=display"> \operatorname { sim } ( i , j ) = \frac { q } { q + r + s } = 1 - d ( i , j ) </script> </div> <p>Persamaan similarity ini disebut dengan <strong>Jaccard coefficient</strong></p> <h4 id=mengukur-jarak-tipe-categorical>Mengukur Jarak Tipe categorical<a class=headerlink href=#mengukur-jarak-tipe-categorical title="Permanent link">&para;</a></h4> <p>Ada beberapa macam pengukuran untuk tipe data categorical <sup id=fnref:3><a class=footnote-ref href=#fn:3>3</a></sup></p> <h5 id=overlay-metric><em>Overlay Metric</em><a class=headerlink href=#overlay-metric title="Permanent link">&para;</a></h5> <p>Ketika semua atribut adalah bertipe nominal, ukuran jarak yang paling sederhana adalah dengan Ovelay Metric (OM) yang dinyatakan dengan </p> <div> <div class=MathJax_Preview> d ( x , y ) = \sum _ { i = 1 } ^ { n } \delta ( a _ { i } ( x ) , a _ { i } ( y ) ) </div> <script type="math/tex; mode=display"> d ( x , y ) = \sum _ { i = 1 } ^ { n } \delta ( a _ { i } ( x ) , a _ { i } ( y ) ) </script> </div> <p>dimana <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> adalah banyaknya atribut, <span><span class=MathJax_Preview>a_i(x)</span><script type=math/tex>a_i(x)</script></span> dan <span><span class=MathJax_Preview>a_i(y)</span><script type=math/tex>a_i(y)</script></span> adalah nilai atribut ke <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> yaitu <span><span class=MathJax_Preview>A_i</span><script type=math/tex>A_i</script></span> dari masing masing objek <span><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span> dan <span><span class=MathJax_Preview>y</span><script type=math/tex>y</script></span>, <span><span class=MathJax_Preview>\delta \ ( a_{ i } ( x ) , a_{ i } ( y ) )</span><script type=math/tex>\delta \ ( a_{ i } ( x ) , a_{ i } ( y ) )</script></span> adalah 0 jika <span><span class=MathJax_Preview>a _ { i } ( x ) = a _ { i } ( y )</span><script type=math/tex>a _ { i } ( x ) = a _ { i } ( y )</script></span> dan 1 jika sebaliknya.</p> <p>OM banyak digunakan oleh instance-based learning dan locally weighted learning. Jelas sekali , ini sedikit beruk untuk mengukur jarak antara masing-masing pasangan sample, karena gagal memanfaatkan tambahan informasi yang diberikan oleh nilai atribut nominal yang bisa membantu dalam generalisasi.</p> <h5 id=value-difference-metric-vdm><em>Value Difference Metric (VDM)</em><a class=headerlink href=#value-difference-metric-vdm title="Permanent link">&para;</a></h5> <p>VDM dikenalkan oleh Standfill and Waltz, versi sederhana dari VDM tanpa skema pembobotan didefinsisikan dengan </p> <div> <div class=MathJax_Preview> d ( x , y ) = \sum _ { i = 1 } ^ { n } \sum _ { c = 1 } ^ { C } \left| P ( c | a _ { i } ( x ) ) - P ( c | a _ { i } ( y ) ) \right | </div> <script type="math/tex; mode=display"> d ( x , y ) = \sum _ { i = 1 } ^ { n } \sum _ { c = 1 } ^ { C } \left| P ( c | a _ { i } ( x ) ) - P ( c | a _ { i } ( y ) ) \right | </script> </div> <p>dimana <span><span class=MathJax_Preview>C</span><script type=math/tex>C</script></span>adalah banyaknya kelas, <span><span class=MathJax_Preview>P(c|a_i(x))</span><script type=math/tex>P(c|a_i(x))</script></span> adalah probabilitas bersyarat dimana kelas <span><span class=MathJax_Preview>x</span><script type=math/tex>x</script></span> adalah <span><span class=MathJax_Preview>c</span><script type=math/tex>c</script></span> dari atribut <span><span class=MathJax_Preview>A_i</span><script type=math/tex>A_i</script></span>, yang memiliki nilai <span><span class=MathJax_Preview>a_i(x)</span><script type=math/tex>a_i(x)</script></span>, <span><span class=MathJax_Preview>P(c|a_i(y))</span><script type=math/tex>P(c|a_i(y))</script></span> adalah probabilitas bersyarat dimana kelas <span><span class=MathJax_Preview>y</span><script type=math/tex>y</script></span> adalah <span><span class=MathJax_Preview>c</span><script type=math/tex>c</script></span> dengan atribut <span><span class=MathJax_Preview>A_i</span><script type=math/tex>A_i</script></span> memiliki nilai <span><span class=MathJax_Preview>a_i(y)</span><script type=math/tex>a_i(y)</script></span></p> <p>VDM mengasumsikan bahwa dua nilai dari atribut adalah lebih dekat jika memiliki klasifikasi sama. Pendekatan lain berbasi probabilitas adalah SFM (Short and Fukunaga Metric) yang kemudian dikembangkan oleh Myles dan Hand dan didefinisikan dengan</p> <div> <div class=MathJax_Preview> d ( x , y ) = \sum _ { c = 1 } ^ { C } \left | P ( c | x ) - P ( c | y ) \right| </div> <script type="math/tex; mode=display"> d ( x , y ) = \sum _ { c = 1 } ^ { C } \left | P ( c | x ) - P ( c | y ) \right| </script> </div> <p>diman probabilitas keanggotaan kelas diestimasi dengan <span><span class=MathJax_Preview>P(c|x)</span><script type=math/tex>P(c|x)</script></span> dan <span><span class=MathJax_Preview>P(c|y)</span><script type=math/tex>P(c|y)</script></span> didekati dengan Naive Bayes, </p> <h5 id=minimum-risk-metric-mrm><em>Minimum Risk Metric (MRM)</em><a class=headerlink href=#minimum-risk-metric-mrm title="Permanent link">&para;</a></h5> <p>Ukuran ini dipresentasikan oleh Blanzieri and Ricci, berbeda dari SFM yaitu meminimumkan selisih antara kesalahan berhingga dan kesalahan asymtotic. MRM meminimumkan risk of misclassification yang didefinisikan dengan</p> <p>$$ d ( x , y ) = \sum _ { c = 1 } ^ { C } P ( c | x ) ( 1 - P ( c | y ) ) $$</p> <h4 id=mengukur-jarak-tipe-ordinal><strong>Mengukur Jarak Tipe Ordinal</strong><a class=headerlink href=#mengukur-jarak-tipe-ordinal title="Permanent link">&para;</a></h4> <p>Nilai-nilai atribut ordinal memiliki urutan atau peringkat, namun besarnya antara nilai-nilai berturut-turut tidak diketahui. Contohnya tingkatan kecil, sedang, besar untuk atribut ukuran. Atribut ordinal juga dapat diperoleh dari diskritisasi atribut numerik dengan membuat rentang nilai ke dalam sejumlah kategori tertentu. Kategori-kategori ini disusun dalam peringkat. Yaitu, rentang atribut numerik dapat dipetakan ke atribut ordinal <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> yang memiliki <span><span class=MathJax_Preview>M_f</span><script type=math/tex>M_f</script></span> state. Misalnya, kisaran suhu atribut skala-skala (dalam Celcius)dapat diatur ke dalam status berikut: −30 hingga −10, −10 hingga 10, 10 hingga 30, masing-masing mewakili kategori suhu dingin, suhu sedang, dan suhu hangat. <span><span class=MathJax_Preview>M</span><script type=math/tex>M</script></span> adalah jumlah keadaan yang dapat dilakukan oleh atribut ordinalmemiliki. State ini menentukan peringkat <span><span class=MathJax_Preview>1, ..., M_f</span><script type=math/tex>1, ..., M_f</script></span></p> <p>Perlakuan untuk atribut ordinal adalah cukup sama dengan atribut numerik ketika menghitung disimilarity antara objek<sup id=fnref:4><a class=footnote-ref href=#fn:4>4</a></sup>. Misalkan <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> adalah atribut-atribut dari atribut ordinal dari <span><span class=MathJax_Preview>n</span><script type=math/tex>n</script></span> objek. Menghitung disimilarity terhadap f fitur sebagai berikut:</p> <ul> <li>Nilai <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> untuk objek ke-<span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> adalah <span><span class=MathJax_Preview>x_{if}</span><script type=math/tex>x_{if}</script></span>, dan <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> memiliki <span><span class=MathJax_Preview>M_f</span><script type=math/tex>M_f</script></span> status urutan , mewakili peringkat <span><span class=MathJax_Preview>1, .., M_f</span><script type=math/tex>1, .., M_f</script></span> Ganti setiap <span><span class=MathJax_Preview>x_{if}</span><script type=math/tex>x_{if}</script></span> dengan peringkatnya, <span><span class=MathJax_Preview>r_{if} \in \{1...M_f\}</span><script type=math/tex>r_{if} \in \{1...M_f\}</script></span></li> <li>Karena setiap atribut ordinal dapat memiliki jumlah state yang berbeda, diperlukan untuk memetakan rentang setiap atribut ke [0,0, 1.0] sehingga setiap atribut memiliki bobot yang sama. Perl melakukan normalisasi data dengan mengganti peringkat <span><span class=MathJax_Preview>r_{if}</span><script type=math/tex>r_{if}</script></span> dengan $$ z _ { i f } = \frac { r _ { i f } - 1 } { M _ { f } - 1 } $$</li> <li>Dissimilarity kemudian dihitung dengan menggunakan ukuran jarak seperti atribut numerik dengan data yang baru setelah ditransformasi $ z _ { i f }$</li> </ul> <h4 id=menghitung-jarak-tipe-campuran><strong>Menghitung Jarak Tipe Campuran</strong><a class=headerlink href=#menghitung-jarak-tipe-campuran title="Permanent link">&para;</a></h4> <p>Menghitung ketidaksamaan antara objek dengan atribut campuran yang berupa nominal, biner simetris, biner asimetris, numerik, atau ordinal yang ada pada kebanyakan databasae dapat dinyatakan dengan memproses semua tipe atribut secara bersamaan<sup id=fnref:5><a class=footnote-ref href=#fn:5>5</a></sup>. Salah satu teknik tersebut menggabungkan atribut yang berbeda ke dalam matriks ketidaksamaan tunggal dan menyatakannya dengan skala interval antar <span><span class=MathJax_Preview>[0,0, 1.0]</span><script type=math/tex>[0,0, 1.0]</script></span>. Misalkan data berisi atribut <span><span class=MathJax_Preview>p</span><script type=math/tex>p</script></span> tipe campuran. Ketidaksamaan (disimilarity ) antara objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> dan <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span> dinyatakan dengan </p> <div> <div class=MathJax_Preview> d ( i , j ) = \frac { \sum _ { f = 1 } ^ { p } \delta _ { i j } ^ { ( f ) } d _ { i j } ^ { ( f ) } } { \sum _ { f = 1 } ^ { p } \delta _ { i j } ^ { ( f ) } } </div> <script type="math/tex; mode=display"> d ( i , j ) = \frac { \sum _ { f = 1 } ^ { p } \delta _ { i j } ^ { ( f ) } d _ { i j } ^ { ( f ) } } { \sum _ { f = 1 } ^ { p } \delta _ { i j } ^ { ( f ) } } </script> </div> <p>dimana <span><span class=MathJax_Preview>\delta_{ij}^{f}=0</span><script type=math/tex>\delta_{ij}^{f}=0</script></span> - jika <span><span class=MathJax_Preview>x_{if}</span><script type=math/tex>x_{if}</script></span> atau <span><span class=MathJax_Preview>x_{jf}</span><script type=math/tex>x_{jf}</script></span> adalah hilang (i.e., tidak ada pengukuran dari atribut f untuk objek <span><span class=MathJax_Preview>i</span><script type=math/tex>i</script></span> atau objek <span><span class=MathJax_Preview>j</span><script type=math/tex>j</script></span>)</p> <ul> <li>jika <span><span class=MathJax_Preview>x_{if}=x_{jf}=0</span><script type=math/tex>x_{if}=x_{jf}=0</script></span> dan </li> <li>atribut <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> adalah binary asymmetric, </li> </ul> <p>selain itu <span><span class=MathJax_Preview>\delta_{ij}^{f}=1</span><script type=math/tex>\delta_{ij}^{f}=1</script></span> </p> <p>Kontribusi dari atribut <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> untuk dissimilarity antara i dan j (yaitu.<span><span class=MathJax_Preview>d_{ij}^{f}</span><script type=math/tex>d_{ij}^{f}</script></span>) dihitung bergantung pada tipenya,</p> <ul> <li>Jika <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> adalah numerik, <span><span class=MathJax_Preview>d_{ij}^{f}=\frac{ \|x _{if}-x_{jf}\|}{max_hx_{hf}-min_hx{hf}}</span><script type=math/tex>d_{ij}^{f}=\frac{ \|x _{if}-x_{jf}\|}{max_hx_{hf}-min_hx{hf}}</script></span>, di mana h menjalankan semua nilai objek yang tidak hilang untuk atribut f</li> <li>Jika <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> adalah nominal atau binary,$d_{ij}^{f}=0 $jika <span><span class=MathJax_Preview>x_{if}=x_{jf}</span><script type=math/tex>x_{if}=x_{jf}</script></span>, sebaliknya <span><span class=MathJax_Preview>d_{ij}^{f}=1</span><script type=math/tex>d_{ij}^{f}=1</script></span></li> <li>Jika <span><span class=MathJax_Preview>f</span><script type=math/tex>f</script></span> adalah ordinal maka hitung rangking <span><span class=MathJax_Preview>r_{if}</span><script type=math/tex>r_{if}</script></span> dan <span><span class=MathJax_Preview>\mathcal z_{if}=\frac {r_{if}-1}{M_f-1}</span><script type=math/tex>\mathcal z_{if}=\frac {r_{if}-1}{M_f-1}</script></span> , dan perlakukan <span><span class=MathJax_Preview>z_{if}</span><script type=math/tex>z_{if}</script></span> sebagai numerik.</li> </ul> <h3 id=referensi>Referensi<a class=headerlink href=#referensi title="Permanent link">&para;</a></h3> <div class=footnote> <hr> <ol> <li id=fn:1> <p>Cielen, Davy, Arno Meysman, and Mohamed Ali. <em>Introducing data science: big data, machine learning, and more, using Python tools</em>. Manning Publications Co., 2016.&#160;<a class=footnote-backref href=#fnref:1 title="Jump back to footnote 1 in the text">&#8617;</a></p> </li> <li id=fn:2> <p>Shirkhorshidi, Ali Seyed, Saeed Aghabozorgi, and Teh Ying Wah. "A comparison study on similarity and dissimilarity measures in clustering continuous data." <em>PloS one</em> 10.12 (2015): e0144059.&#160;<a class=footnote-backref href=#fnref:2 title="Jump back to footnote 2 in the text">&#8617;</a></p> </li> <li id=fn:3> <p>Li, Chaoqun, and Hongwei Li. "A Survey of Distance Metrics for Nominal Attributes." <em>JSW</em> 5.11 (2010): 1262-1269.&#160;<a class=footnote-backref href=#fnref:3 title="Jump back to footnote 3 in the text">&#8617;</a></p> </li> <li id=fn:4> <p>Han, Jiawei, Jian Pei, and Micheline Kamber. <em>Data mining: concepts and techniques</em>. Elsevier, 2011.&#160;<a class=footnote-backref href=#fnref:4 title="Jump back to footnote 4 in the text">&#8617;</a></p> </li> <li id=fn:5> <p>Wilson, D. Randall, and Tony R. Martinez. "Improved heterogeneous distance functions." <em>Journal of artificial intelligence research</em> 6 (1997): 1-34.&#160;<a class=footnote-backref href=#fnref:5 title="Jump back to footnote 5 in the text">&#8617;</a></p> </li> </ol> </div> </article> </div> </div> </main> <footer class=md-footer> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-footer-copyright> <div class=md-footer-copyright__highlight> Copyright &copy; 2020 Mulaab </div> powered by <a href=https://www.mkdocs.org>MkDocs</a> and <a href=https://squidfunk.github.io/mkdocs-material/ > Material for MkDocs</a> </div> <div class=md-footer-social> <link rel=stylesheet href=../assets/fonts/font-awesome.css> <a href=https://github.com/mulaab class="md-footer-social__link fa fa-github-alt"></a> <a href=https://twitter.com/mulaab class="md-footer-social__link fa fa-twitter"></a> </div> </div> </div> </footer> </div> <script src=../assets/javascripts/application.ffb616e8.js></script> <script>app.initialize({version:"1.1.2",url:{base:".."}})</script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML"></script> </body> </html>